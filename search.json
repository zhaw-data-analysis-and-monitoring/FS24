[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analysis and Monitoring FS24",
    "section": "",
    "text": "Welcome\nThe “Data Analysis and Monitoring” module provides an in-depth overview of the methodological skills required for hands-on research and development in any applied data-related or data-heavy project the Master’s level. Students will refine their methodological expertise by examining the different typical phases of data analysis and modelling, starting from data capture and preprocessing the data, through exploratory analysis and predictive modelling, to visualization and communication in the end. They will also acquire the methodological foundations that will underpin the subsequent modules in the MSc CEM programme. The module provides both general methodological skills that cut across disciplines (e.g., scientific theory, computer-aided data processing, and statistics) and specialised knowledge in the context of circular economy.\nThe materials required for the R exercises are available here, with demo files, exercises and solutions.\nThis website was last updated on 2024-02-08 10:59:24.384216.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "preparation.html",
    "href": "preparation.html",
    "title": "Preparation Course",
    "section": "",
    "text": "Install or update R\nIf you haven’t installed R yet, do so now by getting the newest version from CRAN. If you do have R installed, check your Version of R by opening RStudio and typing the following command into the console.\nR.version.string\n## [1] \"R version 4.3.2 (2023-10-31 ucrt)\"\nThis returns the version number of your R installation, whereas the first digit (4) indicates the number of the major release, the second digit (3) indicates the minor release and the last digit (2) refers to the patch release. As a general rule of thumb, you will want to update R if you\nIn the time of writing (February, 2024), the current R Version is 4.3.2 (released on 31.10.2023, see cran.r-project.org). Your installation should therefore not be older than 4.2.0. If it is, make sure that you have updated R before the course. Check these instructions on how to update R",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "preparation.html#install-or-update-r",
    "href": "preparation.html#install-or-update-r",
    "title": "Preparation Course",
    "section": "",
    "text": "don’t have the current major version or\nare lagging two (or more) versions behind the current minor release",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "preparation.html#install-or-update-rstudio",
    "href": "preparation.html#install-or-update-rstudio",
    "title": "Preparation Course",
    "section": "Install or update RStudio",
    "text": "Install or update RStudio\nRStudio is the IDE (integrated development environment) we use in our course to interact with R. There are good alternatives you can use, RStudio simply seems to be the most popular choice. If you want to use your own IDE, please feel free to do so. However, we don’t recommend this if you are a beginner.\nWe recommend updating RStudio to the newest version before the course: check if this is the case by clicking on help &gt; check for updates.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "preparation.html#configure-rstudio",
    "href": "preparation.html#configure-rstudio",
    "title": "Preparation Course",
    "section": "Configure RStudio",
    "text": "Configure RStudio\nNow we will set some RStudio Global options. But first, close all instances of RStudio and restart it (!!!). Then go to Tools &gt; Global options.\n\nR General\n\nDeactivate the option “Restore .RData into workspace at startup”1\nSet “Save workspace to .RData on exit” to “Never”2\n\nCode\n\nActivate the option “Use native pipe operator, |&gt; (requires R 4.1+)”\n\nR Markdown\n\nDeactivate the option “Show output inline for all R Markdown documents”\n\nTerminal\n\nSet option “New terminals open with” to “Git Bash”\n\n\nClick on “Ok” to apply the change and close the options menu.\n\nFolder structure for this course\nBy this point, you probably have created a folder for this course somewhere on your computer. In our example, we assume this folder is located here: C:/Users/yourname/semester2/Module_DAM (mentally replace this with your actual path). Before we dive into the exercises, take a minute to think about how you are going to structure your files in this folder. This course will take place over several weeks, and in each week you will receive or produce various files. We recommend creating a separate folder for each week, and one folder for the case studies, like so:\nCourse Folder (C:\\\\Users\\\\yourname\\\\semester2\\\\Module_DAM)\n ¦--week_1                                                \n ¦--week_2                                                \n ¦--week_3                                                \n |--...                                                \n °--case_studies \nFor the R-exercises we recommend that you create a new RStudio Project each week in subdirectory of the appropriate week. For example, this week your folder structure could look like this:\nFolder Week 1 (C:\\\\Users\\\\yourname\\\\semester2\\\\Module_DAM\\\\week_1)\n ¦--slides.pdf                                                  \n ¦--my_notes.docx                                               \n ¦--seminar_screenshot.jpg                                      \n °---dam-week1-rexercise                                             \n     ¦--dam-week1-rexercise.Rproj                                   \n     ¦--test.csv                                      \n     °--my_solution.qmd   \nNote:\n\nthe RStudio Project is located in a subfolder of C:/Users/yourname/semester1/Module_DAM/week_1 and named dam-week1-rexercise.\ndam-week1-rexercise is the project’s directory name and the project name\nwe realize that dam and the week number is redundant, there is a reason3 for this\nthis means each week is a fresh start (which has pros and cons)\n\n\n\nCreate an RStudio project for the first week\nCreate a new RStudio Project (File &gt; New Project &gt; New Directory &gt; New Project).\n\nClick on “Browse” and switch to your equivalent of the folder C:/Users/yourname/semester1/Module_DAM/week_1 (the project we are about to initiate will be be created in a subdirectory of this folder). Click on “open” to confirm the selection\nIn the field “Directory name”, type dam-week1-rexercise. This will be the name of your RStudio project and it’s parent directory.\nClick on “Create Project”\n\nYou are all set! You can start working on the tasks of exercise 1.\n\n\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science. O’Reilly. https://ebookcentral.proquest.com/lib/zhaw/detail.action?docID=4770093.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "preparation.html#footnotes",
    "href": "preparation.html#footnotes",
    "title": "Preparation Course",
    "section": "",
    "text": "We recommend that you start each RStudio session with a blank slate, as recommended by Wickham and Grolemund (2017) see here↩︎\nIf we don’t restore the workspace at startup, there is no need to save it on exit.↩︎\nYou will see the project names of all your RStudio Projects listed in RStudio. Having the week number in the project name keeps you from getting confused on which project you are working on.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "PrePro.html",
    "href": "PrePro.html",
    "title": "Pre-Processing",
    "section": "",
    "text": "Data Science 2.0 equips students with the essential knowledge and practical skills needed to prepare and enhance their self-collected or sourced data for analysis (preprocessing). This unit focuses on fundamental data processing skills while tackling common challenges in the processing of environmental science data, all through a practical, ‘hands-on’ approach with R exercises. Students will learn to articulate the characteristics of their data sets using the appropriate technical terminology. They will also learn to interpret metadata and critically assess its implications for their own analysis projects. The lesson emphasises critical concepts such as scale levels, data types, time data, and type conversions.\nThis lesson focuses on the central skills required for preprocessing structured data, a fundamental aspect of environmental science research. It covers combining datasets (joins) and transforming them (“reshape”, “split-apply-combine”). Given that data seldom presents itself in a format ready for statistical analysis or information visualisation, students will master the key concepts and R tools required for these often intricate preprocessing tasks, enabling them to execute them effectively.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\nLesson\n\n\nTopic\n\n\n\n\n\n\nPreparation\n\n\n2024-02-20\n\n\nPrePro1\n\n\nPreparation\n\n\n\n\nPrepro 1: Demo\n\n\n2024-02-20\n\n\nPrePro1\n\n\nData Types\n\n\n\n\nPrePro 1: Exercise\n\n\n2024-02-20\n\n\nPrePro1\n\n\nData Types\n\n\n\n\nPrepro 2: Demo\n\n\n2024-02-27\n\n\nPrePro2\n\n\nPiping / Joins\n\n\n\n\nPrepro 2: Exercise A\n\n\n2024-02-27\n\n\nPrePro2\n\n\nPiping / Joins\n\n\n\n\nPrepro 2: Exercise B\n\n\n2024-02-27\n\n\nPrePro2\n\n\nPiping / Joins\n\n\n\n\nPrepro 3: Demo\n\n\n2024-03-05\n\n\nPrePro3\n\n\nSplit-Apply-Combine\n\n\n\n\nPrepro 3: Exercise\n\n\n2024-03-05\n\n\nPrePro3\n\n\nSplit-Apply-Combine\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Pre-Processing"
    ]
  },
  {
    "objectID": "prepro/Prepro0_Vorbereitung.html",
    "href": "prepro/Prepro0_Vorbereitung.html",
    "title": "Preparation",
    "section": "",
    "text": "For Prepro 1 - 3, we will need the following packages: dplyr, ggplot2, lubridate, readr and tidyr. We recommend installing them before the first lesson. Individual packages are typically installed as follows:\n\ninstall.packages(\"dplyr\")     # Quotation marks are mandatory\ninstall.packages(\"ggplot2\")\n...                           # etc.\n\nThe code below will automatically install all uninstalled packages.\n\nipak &lt;- function(pkg) {\n  new.pkg &lt;- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n  if (length(new.pkg)) {\n    install.packages(new.pkg, dependencies = TRUE)\n  }\n}\n\npackages &lt;- c(\"dplyr\", \"ggplot2\", \"lubridate\", \"readr\", \"tidyr\")\n\nipak(packages)\n\nYou can download the datasets for the exercises from Moodle:\n\nPrePro1\nPrePro2\nPrePro3",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preparation</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Demo.html",
    "href": "prepro/Prepro1_Demo.html",
    "title": "Prepro 1: Demo",
    "section": "",
    "text": "Data types",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Prepro 1: Demo</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Demo.html#footnotes",
    "href": "prepro/Prepro1_Demo.html#footnotes",
    "title": "Prepro 1: Demo",
    "section": "",
    "text": "ordered = T can only be specified for the factor() function, not for as.factor(). Otherwise, factor() and as.factor() are very similar.↩︎",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Prepro 1: Demo</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html",
    "href": "prepro/Prepro1_Uebung.html",
    "title": "PrePro 1: Exercise",
    "section": "",
    "text": "Working with RStudio “Project”\nWe recommend using “Projects” within RStudio. RStudio then creates a folder for each project in which the project file is stored (file extension .rproj). If Rscripts are loaded or generated within the project, they are then also stored in the project folder. You can find out more about RStudio Projects here.\nThere are several benefits to using Projects. You can:",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html#working-with-rstudio-project",
    "href": "prepro/Prepro1_Uebung.html#working-with-rstudio-project",
    "title": "PrePro 1: Exercise",
    "section": "",
    "text": "specify the Working Directory without using an explicit path (setwd()). This is useful because the path can change (when collaborating with other users, or executing the script at a later date)\nautomatically cache open scripts and restore open scripts in the next session\nset different project-specific options\nuse version control systems (e.g., git)",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html#working-with-libraries-packages",
    "href": "prepro/Prepro1_Uebung.html#working-with-libraries-packages",
    "title": "PrePro 1: Exercise",
    "section": "Working with libraries / packages",
    "text": "Working with libraries / packages\nR packages have become indispensable. The vast majority of packages are hosted on CRAN and can be easily installed using install.packages(). A very important collection of packages is being developed by RStudio. Tidyverse offers a range of packages that make everyday life enormously easier. We will discuss the “Tidy” universe in more detail later. For now, we can simply install the most important packages from tidyverse (we will only be using a small selection of them today).\nThere are two ways to use a package in R:\n\neither you load it at the beginning of the R-session by means of library(\"dplyr\") (without quotation marks).\nor you call a function by prefixing it with the package name and two colons. dplyr::filter() calls the filter() function from the dplyr package.\n\nThe second method is particularly useful if two different functions with the same name exist in different packages. For example, filter() exists as a function in both the dplyr and stats packages. This is called masking.\nTo get started, we’ll load the necessary packages:\n\nlibrary(\"readr\")\nlibrary(\"lubridate\")",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html#task-1",
    "href": "prepro/Prepro1_Uebung.html#task-1",
    "title": "PrePro 1: Exercise",
    "section": "Task 1",
    "text": "Task 1\nCreate a data.frame with the following data.\n\n\nSample Solution\ndf &lt;- data.frame(\n  AnimalType = c(\"Fox\", \"Bear\", \"Rabbit\", \"Moose\"),\n  Number = c(2, 5, 1, 3),\n  Weight = c(4.4, 40.3, 1.1, 120),\n  Gender = c(\"m\", \"f\", \"m\", \"m\"),\n  Description = c(\"Reddish\", \"Brown, large\", \"Small, with long ears\", \"Long legs, shovel antlers\")\n)\n\n\n\n\n\n\n\nAnimalType\nNumber\nWeight\nGender\nDescription\n\n\n\n\nFox\n2\n4.4\nm\nReddish\n\n\nBear\n5\n40.3\nf\nBrown, large\n\n\nRabbit\n1\n1.1\nm\nSmall, with long ears\n\n\nMoose\n3\n120.0\nm\nLong legs, shovel antlers",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html#task-2",
    "href": "prepro/Prepro1_Uebung.html#task-2",
    "title": "PrePro 1: Exercise",
    "section": "Task 2",
    "text": "Task 2\nWhat types of data were automatically accepted in the last task? Check this using str(), see whether they make sense and convert where necessary.\n\n\nSample Solution\nstr(df)\n## 'data.frame':    4 obs. of  5 variables:\n##  $ AnimalType : chr  \"Fox\" \"Bear\" \"Rabbit\" \"Moose\"\n##  $ Number     : num  2 5 1 3\n##  $ Weight     : num  4.4 40.3 1.1 120\n##  $ Gender     : chr  \"m\" \"f\" \"m\" \"m\"\n##  $ Description: chr  \"Reddish\" \"Brown, large\" \"Small, with long ears\" \"Long legs, shovel antlers\"\ntypeof(df$Number)\n## [1] \"double\"\n# Number was interpreted as `double`, but it is actually an `integer`.\n\ndf$Number &lt;- as.integer(df$Number)",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html#task-3",
    "href": "prepro/Prepro1_Uebung.html#task-3",
    "title": "PrePro 1: Exercise",
    "section": "Task 3",
    "text": "Task 3\nUse the weight column to divide the animals into 3 weight categories:\n\nlight: &lt; 5kg\nmedium: 5 - 100 kg\nheavy: &gt; 100kg\n\n\n\nSample Solution\ndf$WeightClass[df$Weight &gt; 100] &lt;- \"heavy\"\ndf$WeightClass[df$Weight &lt;= 100 & df$Weight &gt; 5] &lt;- \"medium\"\ndf$WeightClass[df$Weight &lt;= 5] &lt;- \"light\"\n\n\nResult:\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnimalType\nNumber\nWeight\nGender\nDescription\nWeightClass\n\n\n\n\nFox\n2\n4.4\nm\nReddish\nlight\n\n\nBear\n5\n40.3\nf\nBrown, large\nmedium\n\n\nRabbit\n1\n1.1\nm\nSmall, with long ears\nlight\n\n\nMoose\n3\n120.0\nm\nLong legs, shovel antlers\nheavy",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html#task-4",
    "href": "prepro/Prepro1_Uebung.html#task-4",
    "title": "PrePro 1: Exercise",
    "section": "Task 4",
    "text": "Task 4\nOn Moodle, you will find a folder called Datasets. Download the file and move it in your project folder. Import the weather.csv file. If you use the RStudio GUI for this, save the import command in your R-Script. Please use a relative path (i.e., not a path starting with C:/, ~/or similar).)\n\n\n\n\n\n\nNote\n\n\n\nI use readr to import csv files and the read_delim function (with underscore) as an alternative to read.csv or read.delim (with a dot). However, this is a personal preference1, and it is up to you which function you use. Remember that the two functions require slightly different parameters.\n\n\n\n\nSample Solution\nweather &lt;- read_delim(\"datasets/prepro/weather.csv\", \",\")\n\n\n\n\n\n\n\nstn\ntime\ntre200h0\n\n\n\n\nABO\n2000010100\n-2.6\n\n\nABO\n2000010101\n-2.5\n\n\nABO\n2000010102\n-3.1\n\n\nABO\n2000010103\n-2.4\n\n\nABO\n2000010104\n-2.5\n\n\nABO\n2000010105\n-3.0\n\n\nABO\n2000010106\n-3.7\n\n\nABO\n2000010107\n-4.4\n\n\nABO\n2000010108\n-4.1\n\n\nABO\n2000010109\n-4.1",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html#task-5",
    "href": "prepro/Prepro1_Uebung.html#task-5",
    "title": "PrePro 1: Exercise",
    "section": "Task 5",
    "text": "Task 5\nCheck the feedback from read_csv(). Have the data been interpreted correctly?\n\n\nSample Solution\n# The 'time' column was interpreted as 'integer'. However, it is \n# obviously a time indication.",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html#task-6",
    "href": "prepro/Prepro1_Uebung.html#task-6",
    "title": "PrePro 1: Exercise",
    "section": "Task 6",
    "text": "Task 6\nThe time column is a date/time with a format of YYYYMMDDHH ( see meta.txt). In order for R to recognise the data in this column as date/time, it must be in the correct format (POSIXct). Therefore, we must tell R what the current format is. Use as.POSIXct() to read the column into R, remembering to specify both format and tz.\n\n\n\n\n\n\nTip\n\n\n\n\nIf no time zone is set, as.POSIXct() sets a default (based on sys.timezone()). In our case, however, these are values in UTC (see metadata.csv)\nas.POSIXct requires a character input: If you receive the error message 'origin' must be supplied (or similar), you have probably tried to input a numeric into the function with.\n\n\n\n\n\nSample Solution\nweather$time &lt;- as.POSIXct(as.character(weather$time), format = \"%Y%m%d%H\", tz = \"UTC\")\n\n\n\n\n\nThe new table should look like this\n\n\nstn\ntime\ntre200h0\n\n\n\n\nABO\n2000-01-01 00:00:00\n-2.6\n\n\nABO\n2000-01-01 01:00:00\n-2.5\n\n\nABO\n2000-01-01 02:00:00\n-3.1\n\n\nABO\n2000-01-01 03:00:00\n-2.4\n\n\nABO\n2000-01-01 04:00:00\n-2.5\n\n\nABO\n2000-01-01 05:00:00\n-3.0\n\n\nABO\n2000-01-01 06:00:00\n-3.7\n\n\nABO\n2000-01-01 07:00:00\n-4.4\n\n\nABO\n2000-01-01 08:00:00\n-4.1\n\n\nABO\n2000-01-01 09:00:00\n-4.1",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html#task-7",
    "href": "prepro/Prepro1_Uebung.html#task-7",
    "title": "PrePro 1: Exercise",
    "section": "Task 7",
    "text": "Task 7\nCreate two new columns for day of week (Monday, Tuesday, etc) and calendar week. Use the newly created POSIXct column and a suitable function from lubridate.\n\n\nSample Solution\nweather$weekday &lt;- wday(weather$time, label = T)\nweather$week &lt;- week(weather$time)\n\n\n\n\n\n\n\nstn\ntime\ntre200h0\nweekday\nweek\n\n\n\n\nABO\n2000-01-01 00:00:00\n-2.6\nSa.\n1\n\n\nABO\n2000-01-01 01:00:00\n-2.5\nSa.\n1\n\n\nABO\n2000-01-01 02:00:00\n-3.1\nSa.\n1\n\n\nABO\n2000-01-01 03:00:00\n-2.4\nSa.\n1\n\n\nABO\n2000-01-01 04:00:00\n-2.5\nSa.\n1\n\n\nABO\n2000-01-01 05:00:00\n-3.0\nSa.\n1\n\n\nABO\n2000-01-01 06:00:00\n-3.7\nSa.\n1\n\n\nABO\n2000-01-01 07:00:00\n-4.4\nSa.\n1\n\n\nABO\n2000-01-01 08:00:00\n-4.1\nSa.\n1\n\n\nABO\n2000-01-01 09:00:00\n-4.1\nSa.\n1",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html#task-8",
    "href": "prepro/Prepro1_Uebung.html#task-8",
    "title": "PrePro 1: Exercise",
    "section": "Task 8",
    "text": "Task 8\nCreate a new column based on the temperature values that classifies the rows into “cold” (below zero degrees) and “warm” (above zero degrees)\n\n\nSample Solution\nweather$temp_cat[weather$tre200h0 &gt; 0] &lt;- \"warm\"\nweather$temp_cat[weather$tre200h0 &lt;= 0] &lt;- \"cold\"\n\n\n\n\n\n\n\nstn\ntime\ntre200h0\nweekday\nweek\ntemp_cat\n\n\n\n\nABO\n2000-01-01 00:00:00\n-2.6\nSa.\n1\ncold\n\n\nABO\n2000-01-01 01:00:00\n-2.5\nSa.\n1\ncold\n\n\nABO\n2000-01-01 02:00:00\n-3.1\nSa.\n1\ncold\n\n\nABO\n2000-01-01 03:00:00\n-2.4\nSa.\n1\ncold\n\n\nABO\n2000-01-01 04:00:00\n-2.5\nSa.\n1\ncold\n\n\nABO\n2000-01-01 05:00:00\n-3.0\nSa.\n1\ncold\n\n\nABO\n2000-01-01 06:00:00\n-3.7\nSa.\n1\ncold\n\n\nABO\n2000-01-01 07:00:00\n-4.4\nSa.\n1\ncold\n\n\nABO\n2000-01-01 08:00:00\n-4.1\nSa.\n1\ncold\n\n\nABO\n2000-01-01 09:00:00\n-4.1\nSa.\n1\ncold",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro1_Uebung.html#footnotes",
    "href": "prepro/Prepro1_Uebung.html#footnotes",
    "title": "PrePro 1: Exercise",
    "section": "",
    "text": "Advantages of read_delim over read.csv: https://stackoverflow.com/a/60374974/4139249↩︎",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>PrePro 1: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Demo.html",
    "href": "prepro/Prepro2_Demo.html",
    "title": "Prepro 2: Demo",
    "section": "",
    "text": "Piping\nWe want to extract the temperature data from a character string (diary), and then convert the Kelvin value into Celsius according to the following formula, before finally calculating the mean of all the values:\n\\[°C = K - 273.15\\]\ndiary &lt;- c(\n  \"The temperature is 310° Kelvin\",\n  \"The temperature is 322° Kelvin\",\n  \"The temperature is 410° Kelvin\"\n)\n\ndiary\n## [1] \"The temperature is 310° Kelvin\" \"The temperature is 322° Kelvin\"\n## [3] \"The temperature is 410° Kelvin\"\nTo do this, we need the substr() function, which can extract part of a character.\n# If the letters were individual _elements_ of a vector, we would subset them like this:\n\ncharvec1 &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\")\ncharvec1[4:6]\n## [1] \"d\" \"e\" \"f\"\n\n# But if these are stored in a single character, we need substr:\ncharvec2 &lt;- \"abcdefgh\"\nsubstr(charvec2, 4, 6)\n## [1] \"def\"\nWe also need the auxiliary subtraction function, substract, which accepts two values, the minuend and the subtrahend:\nsubtract &lt;- function(minuend, subtrahend) {\n  minuend - subtrahend\n}\n\nsubtract(10, 4)\n## [1] 6\nTranslated into R-code, this results in the following operation:\noutput &lt;- mean(subtract(as.numeric(substr(diary, 20, 22)), 273.15))\n#                                         \\_1_/\n#                                  \\________2__________/\n#                       \\___________________3__________/\n#              \\____________________________4____________________/\n#         \\_________________________________5____________________/\n\n# 1. Take diary\n# 2. Extract values 20 to 22 on each line\n# 3. Convert \"character\" to \"numeric\"\n# 4. Subtract 273.15\n# 5. Calculate the mean\nThe whole operation is a little easier to read if it is written down sequentially:\ntemp &lt;- substr(diary, 20, 22)  # 2\ntemp &lt;- as.numeric(temp)       # 3\ntemp &lt;- subtract(temp, 273.15) # 4\noutput &lt;- mean(temp)           # 5\nThe fact that the intermediate results must always be saved and retrieved again in the subsequent operation makes this somewhat cumbersome. This is where “piping” comes into play: It makes the output of one function the first parameter of the subsequent function.\ndiary |&gt;              # 1\n  substr(20, 22) |&gt;   # 2\n  as.numeric() |&gt;     # 3\n  subtract(273.15) |&gt; # 4\n  mean()              # 5\n## [1] 74.18333",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Prepro 2: Demo</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Demo.html#piping",
    "href": "prepro/Prepro2_Demo.html#piping",
    "title": "Prepro 2: Demo",
    "section": "",
    "text": "Important\n\n\n\n\nthe |&gt; pipe operator was first introduced in R 4.1\nIn addition to the base R pipe operator, there is also a very similar1 pipe operator, %&gt;%, in the magrittr package.\nThe Ctrl +Shift+M keyboard shortcut in RStudio inserts a pipe operator.\nBy checking the Use native pipe operator setting in RStudio Settings Tools → Global Options → Code, you can control which pipe operator, |&gt; or %&gt;%, is inserted with the above key combination.\nWe recommend using the base-R pipe operator |&gt;",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Prepro 2: Demo</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Demo.html#joins",
    "href": "prepro/Prepro2_Demo.html#joins",
    "title": "Prepro 2: Demo",
    "section": "Joins",
    "text": "Joins\n\nstudents &lt;- data.frame(\n  Matriculation_No = c(100002, 100003, 200003),\n  Student = c(\"Patrick\", \"Manuela\", \"Eva\"),\n  ZIP = c(8006, 8001, 8820)\n)\n\nstudents\n##   Matriculation_No Student  ZIP\n## 1           100002 Patrick 8006\n## 2           100003 Manuela 8001\n## 3           200003     Eva 8820\n\nlocalities &lt;- data.frame(\n  ZIP = c(8003, 8006, 8810, 8820),\n  LocalityName = c(\"Zurich\", \"Zurich\", \"Horgen\", \"Wadenswil\")\n)\n\nlocalities\n##    ZIP LocalityName\n## 1 8003       Zurich\n## 2 8006       Zurich\n## 3 8810       Horgen\n## 4 8820    Wadenswil\n\n\n# Load library\nlibrary(\"dplyr\")\n\ninner_join(students, localities, by = \"ZIP\")\n##   Matriculation_No Student  ZIP LocalityName\n## 1           100002 Patrick 8006       Zurich\n## 2           200003     Eva 8820    Wadenswil\n\nleft_join(students, localities, by = \"ZIP\")\n##   Matriculation_No Student  ZIP LocalityName\n## 1           100002 Patrick 8006       Zurich\n## 2           100003 Manuela 8001         &lt;NA&gt;\n## 3           200003     Eva 8820    Wadenswil\n\nright_join(students, localities, by = \"ZIP\")\n##   Matriculation_No Student  ZIP LocalityName\n## 1           100002 Patrick 8006       Zurich\n## 2           200003     Eva 8820    Wadenswil\n## 3               NA    &lt;NA&gt; 8003       Zurich\n## 4               NA    &lt;NA&gt; 8810       Horgen\n\nfull_join(students, localities, by = \"ZIP\")\n##   Matriculation_No Student  ZIP LocalityName\n## 1           100002 Patrick 8006       Zurich\n## 2           100003 Manuela 8001         &lt;NA&gt;\n## 3           200003     Eva 8820    Wadenswil\n## 4               NA    &lt;NA&gt; 8003       Zurich\n## 5               NA    &lt;NA&gt; 8810       Horgen\n\n\nstudents &lt;- data.frame(\n  Matriculation_No = c(100002, 100003, 200003),\n  Student = c(\"Patrick\", \"Manuela\", \"Pascal\"),\n  Residence = c(8006, 8001, 8006)\n)\n\nleft_join(students, localities, by = c(\"Residence\" = \"ZIP\"))\n##   Matriculation_No Student Residence LocalityName\n## 1           100002 Patrick      8006       Zurich\n## 2           100003 Manuela      8001         &lt;NA&gt;\n## 3           200003  Pascal      8006       Zurich",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Prepro 2: Demo</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Demo.html#footnotes",
    "href": "prepro/Prepro2_Demo.html#footnotes",
    "title": "Prepro 2: Demo",
    "section": "",
    "text": "see https://stackoverflow.com/q/67633022/4139249↩︎",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Prepro 2: Demo</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Uebung_A.html",
    "href": "prepro/Prepro2_Uebung_A.html",
    "title": "Prepro 2: Exercise A",
    "section": "",
    "text": "Task 1\nRead the weather data from last week weather.csv (source MeteoSchweiz) into R. Make sure that the columns are formatted correctly (stn as a factor, time as POSIXct, tre200h0 as a numeric).\nSample Solution\n# Option 1\nweather &lt;- read_delim(\"datasets/prepro/weather.csv\", \",\")\nweather$stn &lt;- as.factor(weather$stn)\nweather$time &lt;- as.POSIXct(as.character(weather$time), format = \"%Y%m%d%H\", tz = \"UTC\")\nSample Solution\n# Option 2 (for pros)\nweather &lt;- read_csv(\"datasets/prepro/weather.csv\",\n  col_types = cols(\n    col_factor(levels = NULL),\n    col_datetime(format = \"%Y%m%d%H\"),\n    col_double()\n  )\n)",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Prepro 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Uebung_A.html#task-2",
    "href": "prepro/Prepro2_Uebung_A.html#task-2",
    "title": "Prepro 2: Exercise A",
    "section": "Task 2",
    "text": "Task 2\nRead in the metadata.csv dataset as a csv.\n:::{.callout-tip} If umlauts and special characters are not displayed correctly (e.g. the è in Gèneve), this probably has something to do with the character encoding. The file is currently encoded in UTF-8. If special characters are not correctly displayed, R has not recognised this coding and it must be specified in the import function. How this is done depends on the import function used:\n\nPackage functions: readr: locale = locale(encoding = \"UTF-8\")\nBase-R functions: fileEncoding = \"UTF-8\"\n\nIf you do not know how a file is encoded, the following instructions for Windows, Mac and Linux will help: ::\n\n\nSample Solution\nmetadata &lt;- read_delim(\"datasets/prepro/metadata.csv\", delim = \";\", locale = locale(encoding = \"UTF-8\"))",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Prepro 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Uebung_A.html#task-3",
    "href": "prepro/Prepro2_Uebung_A.html#task-3",
    "title": "Prepro 2: Exercise A",
    "section": "Task 3",
    "text": "Task 3\nNow we want to enrich the weather data set with information from metadata. However, we are only interested in the station abbreviation, the name, the x/y coordinates and the sea level. Select these columns.\n\n\nSample Solution\nmetadata &lt;- metadata[, c(\"stn\", \"Name\", \"x\", \"y\", \"Meereshoehe\")]",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Prepro 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Uebung_A.html#task-4",
    "href": "prepro/Prepro2_Uebung_A.html#task-4",
    "title": "Prepro 2: Exercise A",
    "section": "Task 4",
    "text": "Task 4\nNow the metadata can be connected to the weather data set. Which join should we use to do this? And, which attribute can we join?\nUse the join options in dplyr (help via? dplyr::join) to connect the weather data set and the metadata.\n\n\nSample Solution\nweather &lt;- left_join(weather, metadata, by = \"stn\")\n\n# Join type: Left-Join on 'weather', as we are only interested in the stations in the 'weather' dataset.\n# Attribute: \"stn\"",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Prepro 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Uebung_A.html#task-5",
    "href": "prepro/Prepro2_Uebung_A.html#task-5",
    "title": "Prepro 2: Exercise A",
    "section": "Task 5",
    "text": "Task 5\nCreate a new month column (from time). To do this, use the lubridate::month() function.\n\n\nSample Solution\nweather$month &lt;- month(weather$time)",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Prepro 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Uebung_A.html#task-6",
    "href": "prepro/Prepro2_Uebung_A.html#task-6",
    "title": "Prepro 2: Exercise A",
    "section": "Task 6",
    "text": "Task 6\nUse the month column to calculate the average temperature per month.\n\n\nSample Solution\nmean(weather$tre200h0[weather$month == 1])\n## [1] -1.963239\nmean(weather$tre200h0[weather$month == 2])\n## [1] 0.3552632\nmean(weather$tre200h0[weather$month == 3])\n## [1] 2.965054\n\n# etc. for all 12 months",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Prepro 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Uebung_B.html",
    "href": "prepro/Prepro2_Uebung_B.html",
    "title": "Prepro 2: Exercise B",
    "section": "",
    "text": "Task 1\nYou have data from three sensors (sensor1.csv, sensor2.csv, sensor3.csv). Read in the data sets.\nSample Solution\nsensor1 &lt;- read_delim(\"datasets/prepro/sensor1.csv\", \";\")\nsensor2 &lt;- read_delim(\"datasets/prepro/sensor2.csv\", \";\")\nsensor3 &lt;- read_delim(\"datasets/prepro/sensor3.csv\", \";\")",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Prepro 2: Exercise B</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Uebung_B.html#task-2",
    "href": "prepro/Prepro2_Uebung_B.html#task-2",
    "title": "Prepro 2: Exercise B",
    "section": "Task 2",
    "text": "Task 2\nFrom the 3 data frames, create a single data frame that looks like the one shown below. Use two joins from dplyr to connect 3 data.frames. Then tidy up the column names (how can we do that?).\n\n\nSample Solution\nsensor1_2 &lt;- full_join(sensor1, sensor2, \"Datetime\")\n\nsensor1_2 &lt;- rename(sensor1_2, sensor1 = Temp.x, sensor2 = Temp.y)\n\nsensor_all &lt;- full_join(sensor1_2, sensor3, by = \"Datetime\")\n\nsensor_all &lt;- rename(sensor_all, sensor3 = Temp)\n\n\n\n\n\n\n\nDatetime\nsensor1\nsensor2\nsensor3\n\n\n\n\n16102017_1800\n23.5\n13.5\n26.5\n\n\n17102017_1800\n25.4\n24.4\n24.4\n\n\n18102017_1800\n12.4\n22.4\n13.4\n\n\n19102017_1800\n5.4\n12.4\n7.4\n\n\n23102017_1800\n23.5\n13.5\nNA\n\n\n24102017_1800\n21.3\n11.3\nNA",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Prepro 2: Exercise B</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Uebung_B.html#task-3",
    "href": "prepro/Prepro2_Uebung_B.html#task-3",
    "title": "Prepro 2: Exercise B",
    "section": "Task 3",
    "text": "Task 3\nImport the sensor_fail.csv file into R.\n\n\nSample Solution\nsensor_fail &lt;- read_delim(\"datasets/prepro/sensor_fail.csv\", delim = \";\")\n\n\nsensor_fail.csv has a variable SensorStatus: 1 means the sensor is measuring, 0 means the sensor is not measuring. If sensor status = 0, the Temp = 0 value is incorrect. It should be NA (not available). Correct the dataset accordingly.\n\n\n\n\n\nSensor\nTemp\nHum_%\nDatetime\nSensorStatus\n\n\n\n\nSen102\n0.6\n98\n16102017_1800\n1\n\n\nSen102\n0.3\n96\n17102017_1800\n1\n\n\nSen102\n0.0\n87\n18102017_1800\n1\n\n\nSen102\n0.0\n86\n19102017_1800\n0\n\n\nSen102\n0.0\n98\n23102017_1800\n0\n\n\nSen102\n0.0\n98\n24102017_1800\n0\n\n\nSen102\n0.0\n96\n25102017_1800\n1\n\n\nSen103\n-0.3\n87\n26102017_1800\n1\n\n\nSen103\n-0.7\n98\n27102017_1800\n1\n\n\nSen103\n-1.2\n98\n28102017_1800\n1\n\n\n\n\n\n\n\nSample Solution\n# with base-R:\nsensor_fail$Temp_correct[sensor_fail$SensorStatus == 0] &lt;- NA\nsensor_fail$Temp_correct[sensor_fail$SensorStatus != 0] &lt;- sensor_fail$Temp # Warning message can be ignored.\n\n# the same with dplyr:\nsensor_fail &lt;- sensor_fail |&gt;\n  mutate(Temp_correct = ifelse(SensorStatus == 0, NA, Temp))",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Prepro 2: Exercise B</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro2_Uebung_B.html#task-4",
    "href": "prepro/Prepro2_Uebung_B.html#task-4",
    "title": "Prepro 2: Exercise B",
    "section": "Task 4",
    "text": "Task 4\nWhy does it matter if 0 or NA is recorded? Calculate the mean of the temperature / humidity after you have corrected the dataset.\n\n\nSample Solution\n# Mean values of the incorrect sensor data: 0 flows into the calculation\n# and distorts the mean\nmean(sensor_fail$Temp)\n## [1] -0.13\n\n# Mean values of the corrected sensor data: with na.rm = TRUE,\n# NA values are removed from the calculation.\nmean(sensor_fail$Temp_correct, na.rm = TRUE)\n## [1] -0.1857143",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Prepro 2: Exercise B</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Demo.html",
    "href": "prepro/Prepro3_Demo.html",
    "title": "Prepro 3: Demo",
    "section": "",
    "text": "Split Apply Combine",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Prepro 3: Demo</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Demo.html#split-apply-combine",
    "href": "prepro/Prepro3_Demo.html#split-apply-combine",
    "title": "Prepro 3: Demo",
    "section": "",
    "text": "Load data\nLets load the weather data (source MeteoSchweiz) from the last exercise.\n\nweather &lt;- read_delim(\"datasets/prepro/weather.csv\", \",\")\n\nweather &lt;- weather |&gt;\n  mutate(\n    stn = as.factor(stn),\n    time = as.POSIXct(as.character(time), format = \"%Y%m%d%H\")\n  )\n\n\n\nCalculate values\nWe would like to calculate the average of all measured temperature values. To do this, we could use the following command:\n\nmean(weather$tre200h0, na.rm = TRUE)\n## [1] 6.324744\n\nThe option na.rm = T means that NA values should be excluded from the calculation.\nVarious values can be calculated using the same approach (e.g. the maximum (max()), minimum (min()), median (median()) and much more).\nThis approach only works well if we want to calculate values across all observations for a variable (column). As soon as we want to group the observations, it becomes difficult. For example, if we want to calculate the average temperature per month.\n\n\nConvenience Variables\nTo solve this task, the month must first be extracted (the month is the convenience variable). For this we need the lubridate::month() function.\nNow the month convenience variable can be created. Without using dpylr, a new column can be added as follows:\n\nweather$month &lt;- month(weather$time)\n\nWith dplyr (see 3), the same command looks like this:\n\nweather &lt;- mutate(weather, month = month(time))\n\nThe main advantage of dplyr is not yet apparent at this point. However, this will become clear later.\n\n\nCalculate values from groups\nTo calculate the average value per month with base R, you can first create a subset with [] and calculate the average value as follows:\n\nmean(weather$tre200h0[weather$month == 1], na.rm = TRUE)\n## [1] -1.963239\n\nWe have to repeat this every month, which of course is very cumbersome. That is why we use the dplyr package. This, allows us to complete the task (calculate temperature means per month) as follows:\n\nsummarise(group_by(weather, month), temp_average = mean(tre200h0, na.rm = TRUE))\n## # A tibble: 13 × 2\n##    month temp_average\n##    &lt;dbl&gt;        &lt;dbl&gt;\n##  1     1       -1.96 \n##  2     2        0.355\n##  3     3        2.97 \n##  4     4        4.20 \n##  5     5       11.0  \n##  6     6       12.4  \n##  7     7       13.0  \n##  8     8       15.0  \n##  9     9        9.49 \n## 10    10        8.79 \n## 11    11        1.21 \n## 12    12       -0.898\n## 13    NA        2.95\n\n\n\nConcatenate vs. Nest\nTranslated into English, the above operation is as follows:\n\nTake the weather dataset\nForm groups per year (group_by(weather, year))\nCalculate the mean temperature (mean(tre200h0))\n\nThe translation from R -&gt; English looks different because we read the operation in a concatenated form in English (operation 1-&gt;2-&gt;3) while the computer reads it as a nested operation 3(2(1)). To make R closer to English, you can use the |&gt; operator (see 4).\n\n# 1 take the dataset \"weather\"\n# 2 form groups per month\n# 3 calculate the average temperature\n\nsummarise(group_by(weather, month), temp_average = mean(tre200h0))\n#                  \\__1__/\n#         \\___________2__________/\n# \\___________________3________________________________________/\n\n# becomes:\n\nweather |&gt;                                 # 1\n  group_by(month) |&gt;                       # 2\n  summarise(temp_average = mean(tre200h0)) # 3\n\nThis concatenation by means of |&gt; (called pipe) makes the code a lot easier to write and read, and we will use it in the following exercises. Pipe is provided as part of the magrittr package and installed with dplyr.\nThere are several online tutorials about dplyr (see5). Therefore, we will not explain all of these tools in full detail. Instead we will just focus on the important differences for two main functions in dpylr: mutate() and summarise().\n\nsummarise() summarises a data set. The number of observations (rows) is reduced to the number of groups (e.g., one summarised observation (row) per year). In addition, the number of variables (columns) is reduced to those specified in the “summarise” function (e.g., temp_mean).\nmutate adds additional variables (columns) to a data.frame (see example below).\n\n\n# Maximum and minimum temperature per calendar week\nweather_summary &lt;- weather |&gt;               # 1) take the dataset \"weather\"\n  filter(month == 1) |&gt;                     # 2) filter for the month of January\n  mutate(day = day(time)) |&gt;                # 3) create a new column \"day\"\n  group_by(day) |&gt;                          # 4) Use the new column to form groups\n  summarise(\n    temp_max = max(tre200h0, na.rm = TRUE), # 5) Calculate the maximum\n    temp_min = min(tre200h0, na.rm = TRUE)  # 6) Calculate the minimum\n  )\n\nweather_summary\n## # A tibble: 31 × 3\n##      day temp_max temp_min\n##    &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n##  1     1      5.8     -4.4\n##  2     2      2.8     -4.3\n##  3     3      4.2     -3.1\n##  4     4      4.7     -2.8\n##  5     5     11.4     -0.6\n##  6     6      6.7     -1.6\n##  7     7      2.9     -2.8\n##  8     8      0.2     -3.6\n##  9     9      2.1     -8.8\n## 10    10      1.6     -2.4\n## # ℹ 21 more rows",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Prepro 3: Demo</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Demo.html#reshaping-data",
    "href": "prepro/Prepro3_Demo.html#reshaping-data",
    "title": "Prepro 3: Demo",
    "section": "Reshaping data",
    "text": "Reshaping data\n\nWide → long\nTables can be transformed from wide to* long* using tidyr (see 6). This package also works perfectly with piping (|&gt;).\n\nweather_summary |&gt;\n  pivot_longer(c(temp_max, temp_min))\n## # A tibble: 62 × 3\n##      day name     value\n##    &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt;\n##  1     1 temp_max   5.8\n##  2     1 temp_min  -4.4\n##  3     2 temp_max   2.8\n##  4     2 temp_min  -4.3\n##  5     3 temp_max   4.2\n##  6     3 temp_min  -3.1\n##  7     4 temp_max   4.7\n##  8     4 temp_min  -2.8\n##  9     5 temp_max  11.4\n## 10     5 temp_min  -0.6\n## # ℹ 52 more rows\n\nIn the pivot_longer() command, we have to define which columns should be summarised (in this case: temp_max, temp_min, temp_mean). Alternatively, we can specify which columns we do not want to summarise:\n\nweather_summary |&gt;\n  pivot_longer(-day)\n## # A tibble: 62 × 3\n##      day name     value\n##    &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt;\n##  1     1 temp_max   5.8\n##  2     1 temp_min  -4.4\n##  3     2 temp_max   2.8\n##  4     2 temp_min  -4.3\n##  5     3 temp_max   4.2\n##  6     3 temp_min  -3.1\n##  7     4 temp_max   4.7\n##  8     4 temp_min  -2.8\n##  9     5 temp_max  11.4\n## 10     5 temp_min  -0.6\n## # ℹ 52 more rows\n\nIf we want to set the names of new columns (instead of name and value), this can be achieved by using names_to or values_to:\n\nweather_summary_long &lt;- weather_summary |&gt;\n  pivot_longer(-day, names_to = \"MeasurementType\", values_to = \"MeasurementValue\")\n\nThe first 6 lines of weather_summary_long:\n\n\n\n\n\nday\nMeasurementType\nMeasurementValue\n\n\n\n\n1\ntemp_max\n5.8\n\n\n1\ntemp_min\n-4.4\n\n\n2\ntemp_max\n2.8\n\n\n2\ntemp_min\n-4.3\n\n\n3\ntemp_max\n4.2\n\n\n3\ntemp_min\n-3.1\n\n\n\n\n\nThe first 6 lines of weather_sry:\n\n\n\n\n\nday\ntemp_max\ntemp_min\n\n\n\n\n1\n5.8\n-4.4\n\n\n2\n2.8\n-4.3\n\n\n3\n4.2\n-3.1\n\n\n4\n4.7\n-2.8\n\n\n5\n11.4\n-0.6\n\n\n6\n6.7\n-1.6\n\n\n\n\n\nNote: weather_summary_long comprises 62 observations (rows), which is twice as much as weather_summary, because we have combined two of the columns.\n\nnrow(weather_summary)\n## [1] 31\nnrow(weather_summary_long)\n## [1] 62\n\nLong tables are more practical in many situations. For example, visualising using ggplot2 (you will learn about this package in the “InfoVis” block) is much easier with long tables.\n\nggplot(weather_summary_long, aes(day, MeasurementValue, colour = MeasurementType)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\nLong → wide\nThe counterpart to pivot_longer is pivot_wider. This function allows us to convert a long table into a wide one. To do this, we must specify in names_from which column the new column names should be created from (names_from) and which column the values should originate from (values_from):\n\nweather_summary_long |&gt;\n  pivot_wider(names_from = MeasurementType, values_from = MeasurementValue)\n## # A tibble: 31 × 3\n##      day temp_max temp_min\n##    &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n##  1     1      5.8     -4.4\n##  2     2      2.8     -4.3\n##  3     3      4.2     -3.1\n##  4     4      4.7     -2.8\n##  5     5     11.4     -0.6\n##  6     6      6.7     -1.6\n##  7     7      2.9     -2.8\n##  8     8      0.2     -3.6\n##  9     9      2.1     -8.8\n## 10    10      1.6     -2.4\n## # ℹ 21 more rows\n\nFor comparison: We have to plot each column individually in ggplot2 for a wide table. While this is not a problem when we are only working with a few variables, like here, with a high number this quickly becomes tedious.\n\nggplot(weather_summary) +\n  geom_line(aes(day, temp_max)) +\n  geom_line(aes(day, temp_min))\n\n\n\n\n\n\n\n\n\n\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science. O’Reilly. https://ebookcentral.proquest.com/lib/zhaw/detail.action?docID=4770093.",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Prepro 3: Demo</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Demo.html#footnotes",
    "href": "prepro/Prepro3_Demo.html#footnotes",
    "title": "Prepro 3: Demo",
    "section": "",
    "text": "http://r4ds.had.co.nz/↩︎\n https://ebookcentral.proquest.com/lib/zhaw/detail.action?docID=4770093↩︎\n Wickham and Grolemund (2017), Chapter 10 /http://r4ds.had.co.nz/transform.html↩︎\n Wickham and Grolemund (2017), Chapter 14 / http://r4ds.had.co.nz/pipes.html↩︎\nWickham and Grolemund (2017), Chapter 10 / http://r4ds.had.co.nz/transform.html, or Hands-on dplyr tutorial..↩︎\n https://r4ds.had.co.nz/tidy-data.html#pivoting↩︎",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Prepro 3: Demo</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Uebung.html",
    "href": "prepro/Prepro3_Uebung.html",
    "title": "Prepro 3: Exercise",
    "section": "",
    "text": "Task 1\nYou have a dataset, sensors_combined.csv, with temperature values from three different sensors. Import it as a csv into R (as sensors_combined).\nReformat the datetime column to POSIXct. Use the as.POSIXct function (read it in using?strftime()) to determine the specific format (the template).\nSample Solution\nlibrary(\"readr\")\n\nsensors_combined &lt;- read_delim(\"datasets/prepro/sensors_combined.csv\", \",\")\n\nsensors_combined$Datetime &lt;- as.POSIXct(sensors_combined$Datetime, format = \"%d%m%Y_%H%M\")",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Prepro 3: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Uebung.html#task-2",
    "href": "prepro/Prepro3_Uebung.html#task-2",
    "title": "Prepro 3: Exercise",
    "section": "Task 2",
    "text": "Task 2\nConvert the table to a long format (use the pivot_longer function from tidyr) and save the output as sensors_long.\nTips:\n\nIn the cols argument, you can list the columns that should be pivoted.\nAlternatively, you can indicate (by placing a minus sign in front, -) the column that should not be pivoted.\nIn either case, you do not need to put the columns in quotation marks or end them with the $sign.\n\n\n\nSample Solution\nlibrary(\"tidyr\")\n\n# Option 1 (Deselect columns)\nsensors_long &lt;- pivot_longer(sensors_combined, -Datetime)\n\n# Option 2 (Select columns)\nsensors_long &lt;- pivot_longer(sensors_combined, c(sensor1:sensor3))",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Prepro 3: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Uebung.html#task-3",
    "href": "prepro/Prepro3_Uebung.html#task-3",
    "title": "Prepro 3: Exercise",
    "section": "Task 3",
    "text": "Task 3\nGroup sensors_long according to the new column where the sensor information is contained (default: name) with group_by and calculate the average temperature for each sensor (summarise). Note: Both functions are part of the dplyr package.\nThe output will look like this:\n\n\nSample Solution\nlibrary(\"dplyr\")\n\nsensors_long |&gt;\n  group_by(name) |&gt;\n  summarise(temp_mean = mean(value, na.rm = TRUE))\n## # A tibble: 3 × 2\n##   name    temp_mean\n##   &lt;chr&gt;       &lt;dbl&gt;\n## 1 sensor1      14.7\n## 2 sensor2      12.0\n## 3 sensor3      14.4",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Prepro 3: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Uebung.html#task-4",
    "href": "prepro/Prepro3_Uebung.html#task-4",
    "title": "Prepro 3: Exercise",
    "section": "Task 4",
    "text": "Task 4\nCreate a new convenience variable, month, for sensors_long (Tip: use the month function from lubridate). Now group by month and sensor and calculate the mean temperature.\n\n\nSample Solution\nlibrary(\"lubridate\")\n\nsensors_long |&gt;\n  mutate(month = month(Datetime)) |&gt;\n  group_by(month, name) |&gt;\n  summarise(temp_mean = mean(value, na.rm = TRUE))\n## # A tibble: 6 × 3\n## # Groups:   month [2]\n##   month name    temp_mean\n##   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n## 1    10 sensor1     14.7 \n## 2    10 sensor2     12.7 \n## 3    10 sensor3     14.4 \n## 4    11 sensor1    NaN   \n## 5    11 sensor2      8.87\n## 6    11 sensor3    NaN",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Prepro 3: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Uebung.html#task-5",
    "href": "prepro/Prepro3_Uebung.html#task-5",
    "title": "Prepro 3: Exercise",
    "section": "Task 5",
    "text": "Task 5\nNow download the weather.csv dataset (source MeteoSwiss) and import it as a .csv with the correct column types (stn as a factor, time as POSIXct, tre200h0 as double).\n\n\nSample Solution\nweather &lt;- read_delim(\"datasets/prepro/weather.csv\", col_types = cols(col_factor(), col_datetime(\"%Y%m%d%H\"), col_double()), \",\")",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Prepro 3: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Uebung.html#task-6",
    "href": "prepro/Prepro3_Uebung.html#task-6",
    "title": "Prepro 3: Exercise",
    "section": "Task 6",
    "text": "Task 6\nNow create a convenience variable for the calendar week for each measurement (lubridate::isoweek). Then calculate the average temperature value for each calendar week.\n\n\nSample Solution\nweather_summary &lt;- weather |&gt;\n  mutate(week = isoweek(time)) |&gt;\n  group_by(week) |&gt;\n  summarise(\n    temp_mean = mean(tre200h0, na.rm = TRUE)\n  )\n\n\nNext visualise the result:\n\nSample Solution\nplot(weather_summary$week, weather_summary$temp_mean, type = \"l\")",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Prepro 3: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Uebung.html#task-7",
    "href": "prepro/Prepro3_Uebung.html#task-7",
    "title": "Prepro 3: Exercise",
    "section": "Task 7",
    "text": "Task 7\nIn the previous task, we calculated the average temperature per calendar week over all years (2000 and 2001). However, if we want to compare the years with each other, we have to create the year as an additional convenience variable and group it accordingly. Try this with the weather data and then visualise the output.\n\n\nSample Solution\nweather_summary2 &lt;- weather |&gt;\n  mutate(\n    week = week(time),\n    year = year(time)\n    ) |&gt;\n  group_by(year, week) |&gt;\n  summarise(\n    temp_mean = mean(tre200h0, na.rm = TRUE)\n  )\n\n\n\n\nSample Solution\nplot(weather_summary2$week, weather_summary2$temp_mean, type = \"l\")\n\n\n\n\n\n\n\n\nFigure 9.1: Base plot does not like long tables and makes a continuous line out of the two years",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Prepro 3: Exercise</span>"
    ]
  },
  {
    "objectID": "prepro/Prepro3_Uebung.html#task-8",
    "href": "prepro/Prepro3_Uebung.html#task-8",
    "title": "Prepro 3: Exercise",
    "section": "Task 8",
    "text": "Task 8\nTransfer the output from the last exercise to a wide table. Now the two years can be compared much more easily.\n\n\nSample Solution\nweather_summary2 &lt;- weather_summary2 |&gt;\n  pivot_wider(names_from = year, values_from = temp_mean,names_prefix = \"year\")\n\n\n\n\nSample Solution\nplot(weather_summary2$week, weather_summary2$year2000, type = \"l\",col = \"blue\")\nlines(weather_summary2$week, weather_summary2$year2001, type = \"l\",col = \"red\")",
    "crumbs": [
      "Pre-Processing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Prepro 3: Exercise</span>"
    ]
  },
  {
    "objectID": "InfoVis.html",
    "href": "InfoVis.html",
    "title": "Information Visualisation",
    "section": "",
    "text": "InfoVis 1\nConventional inferential statistics are typically employed to confirm hypotheses. These hypotheses are derived from established theories and are then tested through experiments to determine whether they should be accepted or rejected. Conversely, Exploratory Data Analysis (EDA) takes an antagonistic approach, by first seeking out patterns and relationships within the data, which can subsequently inform the development of hypotheses for testing. This module presents the traditional five-step process of Exploratory Data Analysis as established by Tukey in 1980, culminating in a transition to its contemporary application through Visual Analytics.",
    "crumbs": [
      "Information Visualisation"
    ]
  },
  {
    "objectID": "InfoVis.html#infovis-2",
    "href": "InfoVis.html#infovis-2",
    "title": "Information Visualisation",
    "section": "InfoVis 2",
    "text": "InfoVis 2\nInformation visualisation stands out as a flexible, powerful, and efficient tool for exploratory data analysis. Beyond the well-known scatter plots and histograms, there are innovative visualisation techniques like parallel coordinate plots, tree maps, and chord diagrams that provide unique perspectives for analysing increasingly large and complex datasets. In this lesson, students get to know a number of information visualisation types, learn to design them in a targeted manner and to create them themselves.",
    "crumbs": [
      "Information Visualisation"
    ]
  },
  {
    "objectID": "infovis/Infovis0_Vorbereitung.html",
    "href": "infovis/Infovis0_Vorbereitung.html",
    "title": "Preparation",
    "section": "",
    "text": "As part of InfoVis 1 - 2, we will need several R packages. We recommend installing these before the first lesson. Similar to the preparation section in the pre-processing tutorial, you can use the following code to automatically install any packages that are not already installed.\n\nipak &lt;- function(pkg) {\n  new.pkg &lt;- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n  if (length(new.pkg)) {\n    install.packages(new.pkg, dependencies = TRUE)\n  }\n}\n\npackages &lt;- c(\"dplyr\", \"ggplot2\", \"lubridate\", \"readr\", \"scales\", \"tidyr\")\n\nipak(packages)\n\nYou can download the datasets for the exercises from Moodle:\n\nInfoVis1\nInfoVis2",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Preparation</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Demo.html",
    "href": "infovis/Infovis1_Demo.html",
    "title": "Infovis 1: Demo A",
    "section": "",
    "text": "Base-plot vs. ggplot\nWe can create a scatterplot in “Base-R” to compare dates and temperatures as follows:\nplot(temperature$time, temperature$SHA, type = \"l\", col = \"red\")\nlines(temperature$time, temperature$ZER, col = \"blue\")\nIn ggplot, the approach is more nuanced. A plot begins with ggplot(). This command specifies the dataset (data =) and the variables within the dataset that influence the plot (mapping = aes()).\n# Dataset: \"temperature\" | Influencing variables: \"time\" and \"temp\"\nggplot(data = temperature, mapping = aes(time, SHA))\nIn ggplot, at least one “layer” is required to represent data, such as geom_point() for scatterplots, using the + operator. Unlike “piping” (|&gt;), a layer is added with +.\nggplot(data = temperature, mapping = aes(time, SHA)) +\n  # Layer: \"geom_point\" corresponds to points in a scatterplot\n  geom_point()\nSince inputs are expected in the order of data = followed by mapping = in ggplot, we can omit these specifications.\nggplot(temperature, aes(time, SHA)) +\n  geom_point()",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infovis 1: Demo A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Demo.html#long-vs.-wide",
    "href": "infovis/Infovis1_Demo.html#long-vs.-wide",
    "title": "Infovis 1: Demo A",
    "section": "Long vs. wide",
    "text": "Long vs. wide\nAs mentioned in PrePro 2, ggplot2 is designed for long tables. Therefore, we need to transform the wide table into a long format:\n\ntemperature_long &lt;- pivot_longer(temperature, -time, names_to = \"station\", values_to = \"temp\")\n\nTo colour-code different weather stations, we define variables that will influence the graphic, which are incorporated in the aes() function:\n\nggplot(temperature_long, aes(time, temp, colour = station)) +\n  geom_point()\n\n\n\n\n\n\n\n\nWe can also add additional layers with lines:\n\nggplot(temperature_long, aes(time, temp, colour = station)) +\n  geom_point() +\n  geom_line()",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infovis 1: Demo A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Demo.html#labels",
    "href": "infovis/Infovis1_Demo.html#labels",
    "title": "Infovis 1: Demo A",
    "section": "Labels",
    "text": "Labels\nNext, we’ll refine our plot by adding axis labels and a title. Additionally, we’ve chosen to remove the points (geom_point()) as they don’t align with my preferred visualisation style.\n\nggplot(temperature_long, aes(time, temp, colour = station)) +\n  geom_line() +\n  labs(\n    x = \"Time\",\n    y = \"Temperature in degrees C°\",\n    title = \"Temperature Data Switzerland\",\n    subtitle = \"2001 to 2002\",\n    colour = \"Station\"\n  )",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infovis 1: Demo A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Demo.html#split-apply-combine",
    "href": "infovis/Infovis1_Demo.html#split-apply-combine",
    "title": "Infovis 1: Demo A",
    "section": "Split Apply Combine",
    "text": "Split Apply Combine\nIn our plot, the hourly data points are too detailed for a two-year visualisation. Using the Split Apply Combine technique (covered in PrePro 3), we can adjust the data resolution:\n\ntemperature_day &lt;- temperature_long |&gt;\n  mutate(time = as.Date(time))\n\ntemperature_day\n## # A tibble: 35,088 × 3\n##    time       station  temp\n##    &lt;date&gt;     &lt;chr&gt;   &lt;dbl&gt;\n##  1 2000-01-01 SHA       0.2\n##  2 2000-01-01 ZER      -8.8\n##  3 2000-01-01 SHA       0.3\n##  4 2000-01-01 ZER      -8.7\n##  5 2000-01-01 SHA       0.3\n##  6 2000-01-01 ZER      -9  \n##  7 2000-01-01 SHA       0.3\n##  8 2000-01-01 ZER      -8.7\n##  9 2000-01-01 SHA       0.4\n## 10 2000-01-01 ZER      -8.5\n## # ℹ 35,078 more rows\n\ntemperature_day &lt;- temperature_day |&gt;\n  group_by(station, time) |&gt;\n  summarise(temp = mean(temp))\n\ntemperature_day\n## # A tibble: 1,462 × 3\n## # Groups:   station [2]\n##    station time        temp\n##    &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;\n##  1 SHA     2000-01-01  1.25\n##  2 SHA     2000-01-02  1.73\n##  3 SHA     2000-01-03  1.59\n##  4 SHA     2000-01-04  1.78\n##  5 SHA     2000-01-05  4.66\n##  6 SHA     2000-01-06  3.49\n##  7 SHA     2000-01-07  3.87\n##  8 SHA     2000-01-08  3.28\n##  9 SHA     2000-01-09  3.24\n## 10 SHA     2000-01-10  3.24\n## # ℹ 1,452 more rows",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infovis 1: Demo A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Demo.html#adjusting-the-xy-axes",
    "href": "infovis/Infovis1_Demo.html#adjusting-the-xy-axes",
    "title": "Infovis 1: Demo A",
    "section": "Adjusting the X/Y Axes",
    "text": "Adjusting the X/Y Axes\nYou can also influence the x/y axes. You first have to determine what type of axis the plot has (in its default setting, ggplot automatically selects the axis type based on the nature of the data).\nFor our y-axis, which consists of numerical data, ggplot uses scale_y_continuous(). Other axis types can be found at ggplot2.tidyverse.org (scale_x_something or scale_y_something).\n\nggplot(temperature_day, aes(time, temp, colour = station)) +\n  geom_line() +\n  labs(\n    x = \"Time\",\n    y = \"Temperature in degrees C\",\n    title = \"Temperature Data Switzerland\",\n    subtitle = \"2001 to 2002\",\n    color = \"Station\"\n  ) +\n  scale_y_continuous(limits = c(-30, 30)) # determine y-axis section\n\n\n\n\n\n\n\n\nThis can also be done for the x-axis. Our x-axis consists of date information. ggplot calls this: scale_x_date().\n\nggplot(temperature_day, aes(time, temp, colour = station)) +\n  geom_line() +\n  labs(\n    x = \"Time\",\n    y = \"Temperature in degrees C\",\n    title = \"Temperature Data Switzerland\",\n    subtitle = \"2001 to 2002\",\n    color = \"Station\"\n  ) +\n  scale_y_continuous(limits = c(-30, 30)) +\n  scale_x_date(\n    date_breaks = \"3 months\",\n    date_labels = \"%b\"\n  )",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infovis 1: Demo A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Demo.html#customising-themes",
    "href": "infovis/Infovis1_Demo.html#customising-themes",
    "title": "Infovis 1: Demo A",
    "section": "Customising Themes",
    "text": "Customising Themes\nThe theme function in ggplot allows us to alter the general layout of plots. For instance, theme_classic() changes the plot’s style to a more traditional look, which is ideal for formal reports or publications. This theme can be applied either to individual plots or set as a default for all plots within a session.\nApplying to a single Plot:\n\nggplot(temperature_day, aes(time, temp, colour = station)) +\n  geom_line() +\n  theme_classic()\n\nGlobal setting (for all subsequent plots in the current session):\n\ntheme_set(theme_classic())",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infovis 1: Demo A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Demo.html#facets-small-multiples",
    "href": "infovis/Infovis1_Demo.html#facets-small-multiples",
    "title": "Infovis 1: Demo A",
    "section": "Facets / Small Multiples",
    "text": "Facets / Small Multiples\nggplot also offers powerful functions for creating “Small multiples” using facet_wrap() (or facet_grid(), more on this later). These functions divide the main plot into smaller subplots based on a specified variable, denoted by the tilde symbol “~”.\n\nggplot(temperature_day, aes(time, temp, colour = station)) +\n  geom_line() +\n  labs(\n    x = \"Time\",\n    y = \"Temperature in °C\",\n    title = \"Temperature Data of Switzerland\",\n    subtitle = \"2001 to 2002\",\n    colour = \"Station\"\n  ) +\n  scale_y_continuous(limits = c(-30, 30)) +\n  scale_x_date(\n    date_breaks = \"3 months\",\n    date_labels = \"%b\"\n  ) +\n  facet_wrap(~station)\n\n\n\n\n\n\n\n\nfacet_wrap can also be customised further, such as by setting the number of facets per row with ncol =.\nIn addition, since the station names are displayed above each facet, we no longer require the legend. This is achieved with theme(legend.position=\"none\").\n\nggplot(temperature_day, aes(time, temp, colour = station)) +\n  geom_line() +\n  labs(\n    x = \"Time\",\n    y = \"Temperature in °C\",\n    title = \"Temperature Data of Switzerland\",\n    subtitle = \"2001 to 2002\"\n  ) +\n  scale_y_continuous(limits = c(-30, 30)) +\n  scale_x_date(\n    date_breaks = \"3 months\",\n    date_labels = \"%b\"\n  ) +\n  facet_wrap(~station, ncol = 1) +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infovis 1: Demo A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Demo.html#storing-and-exporting-plots",
    "href": "infovis/Infovis1_Demo.html#storing-and-exporting-plots",
    "title": "Infovis 1: Demo A",
    "section": "Storing and Exporting Plots",
    "text": "Storing and Exporting Plots\nLike data.frames and other objects, a complete ggplot plot can be stored in a variable. This is useful for exporting the plot (as PNG, JPG, etc.) or for progressively enhancing it, as shown in this example.\n\np &lt;- ggplot(temperature_day, aes(time, temp, colour = station)) +\n  geom_line() +\n  labs(\n    x = \"Zeit\",\n    y = \"Temperatur in Grad C°\",\n    title = \"Temperaturdaten Schweiz\",\n    subtitle = \"2001 bis 2002\"\n  ) +\n  scale_y_continuous(limits = c(-30, 30)) +\n  scale_x_date(\n    date_breaks = \"3 months\",\n    date_labels = \"%b\"\n  ) +\n  facet_wrap(~station, ncol = 1)\n# At this point, theme(legend.position=\"none\") was removed\n\nTo save the plot as a PNG file (without specifying “plot =”, the last plot is simply saved):\n\nggsave(filename = \"plot.png\", plot = p)\n\nTo add a layer or option to an existing plot stored in a variable:\n\np +\n  theme(legend.position = \"none\")\n\nAs is typical with R, the modification made to the plot is not automatically saved; it only shows the outcome of the change. To permanently incorporate this change into my plot stored in the variable, we need to overwrite the variable with the updated plot:\n\np &lt;- p +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infovis 1: Demo A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Demo.html#smoothing",
    "href": "infovis/Infovis1_Demo.html#smoothing",
    "title": "Infovis 1: Demo A",
    "section": "Smoothing",
    "text": "Smoothing\nThe geom_smooth() function in ggplot can add trend lines to scatter plots. It is possible to select the underlying statistical method that is applied, yet by default, for datasets with fewer than 1,000 observations, ggplot defaults to using the stats::loess method. For larger datasets, it switches to mgcv::gam.\n\np &lt;- p +\n  geom_smooth(colour = \"black\")\np",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infovis 1: Demo A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Uebung.html",
    "href": "infovis/Infovis1_Uebung.html",
    "title": "Infovis 1: Exercise",
    "section": "",
    "text": "Task 1\nYour first task is to recreate the following plot from Kovic (2014) using ggplot and the tagi_data_kanton.csv dataset:\nHere’s are some tips to get you started:\nSample Solution\n# Solution to Task 1\n\nplot1 &lt;- ggplot(canton, aes(auslanderanteil, ja_anteil)) +\n  geom_point() +\n  coord_fixed(1) +\n  scale_y_continuous(breaks = c(0, 0.1, 0.3, 0.5, 0.7), limits = c(0, 0.7)) +\n  scale_x_continuous(breaks = c(0, 0.1, 0.3, 0.5, 0.7), limits = c(0, 0.7)) +\n  labs(y = \"Proportion of Yes Votes\", x = \"Foreigner Proportion\")\n\nplot1",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Infovis 1: Exercise</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Uebung.html#task-1",
    "href": "infovis/Infovis1_Uebung.html#task-1",
    "title": "Infovis 1: Exercise",
    "section": "",
    "text": "Create a ggplot object with ggplot(canton, aes(auslanderanteil, ja_anteil)), then add a point layer with geom_point().\nUse coord_fixed() to set a fixed ratio (1:1) between the axes.\nOptionally, you can:\n\nSet the axis start and end values with scale_y_continuous or scale_x_continuous.\nManually set the breaks (0.0, 0.1…0.7) within scale_*_continuous as in Kovic (2014).\nUse labs() to label the axes.",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Infovis 1: Exercise</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Uebung.html#task-2",
    "href": "infovis/Infovis1_Uebung.html#task-2",
    "title": "Infovis 1: Exercise",
    "section": "Task 2",
    "text": "Task 2\nNext, replicate the following plot from Kovic (2014) using ggplot:\nHere’s a tip:\n\nUse geom_smooth.\n\n\n\nSample Solution\n# Solution to Task 2\n\nplot1 +\n  geom_smooth()",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Infovis 1: Exercise</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Uebung.html#task-3",
    "href": "infovis/Infovis1_Uebung.html#task-3",
    "title": "Infovis 1: Exercise",
    "section": "Task 3",
    "text": "Task 3\nNow, let’s import the municipal data tagi_data_gemeinden.csv.\nReplicate the following plot from Kovic (2014) using ggplot and the tagi_data_gemeinden.csv dataset:\nHere are some tips:\n\nUse geom_point().\nUse labs().\nUse coord_fixed().\n\n\n\nSample Solution\n# Solution to Task 3\n\nmunicipality &lt;- read_delim(\"datasets/infovis/tagi_data_gemeinden.csv\", \",\")\n\nplot2 &lt;- ggplot(municipality, aes(anteil_ausl, anteil_ja)) +\n  geom_point() +\n  labs(x = \"Foreigner Proportion\", y = \"Proportion of Yes Votes\") +\n  coord_fixed(1) +\n  lims(x = c(0, 1), y = c(0, 1))\n\nplot2",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Infovis 1: Exercise</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Uebung.html#task-4",
    "href": "infovis/Infovis1_Uebung.html#task-4",
    "title": "Infovis 1: Exercise",
    "section": "Task 4",
    "text": "Task 4\nReplicate the following plot from Kovic (2014) using ggplot and the tagi_data_gemeinden.csv dataset:\nHere’s a tip:\n\nUse geom_smooth.\n\n\n\nSample Solution\n# Solution to Task 4\n\nplot2 +\n  geom_smooth()",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Infovis 1: Exercise</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Uebung.html#task-5",
    "href": "infovis/Infovis1_Uebung.html#task-5",
    "title": "Infovis 1: Exercise",
    "section": "Task 5",
    "text": "Task 5\nReplicate the following plot from Kovic (2014) using ggplot and the tagi_data_gemeinden.csv dataset:\nHere’s a tip:\n\nUse facet_wrap to display a separate plot for each canton.\n\n\n\nSample Solution\n# Solution to Task 5\n\nplot3 &lt;- plot2 +\n  facet_wrap(~kanton)\nplot3",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Infovis 1: Exercise</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Uebung.html#task-6",
    "href": "infovis/Infovis1_Uebung.html#task-6",
    "title": "Infovis 1: Exercise",
    "section": "Task 6",
    "text": "Task 6\nReplicate the following plot from Kovic (2014) using ggplot and the tagi_data_gemeinden.csv dataset:\nHere’s a tip:\n\nUse geom_smooth.\n\n\n\nSample Solution\n# Solution to Task 6\n\nplot3 +\n  geom_smooth()",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Infovis 1: Exercise</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Uebung.html#task-7",
    "href": "infovis/Infovis1_Uebung.html#task-7",
    "title": "Infovis 1: Exercise",
    "section": "Task 7",
    "text": "Task 7\nReplicate the following plot from Kovic (2014) using ggplot and the tagi_data_gemeinden.csv dataset:\nHere’s a tip:\n\nUse facet_wrap\n\n\n\nSample Solution\n# Solution to Task 7\n\nplot4 &lt;- plot2 +\n  facet_wrap(~quantile)\nplot4",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Infovis 1: Exercise</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Uebung.html#task-8",
    "href": "infovis/Infovis1_Uebung.html#task-8",
    "title": "Infovis 1: Exercise",
    "section": "Task 8",
    "text": "Task 8\nReplicate the following plot from Kovic (2014) using ggplot and the tagi_data_gemeinden.csv dataset:\nHere’s a tip:\n\nUse geom_smooth.\n\n\n\nSample Solution\n# Solution to Task 8\n\nplot4 +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\n\n\n\nKovic, Marko. 2014. “Je Weniger Ausländer, Desto Mehr Ja-Stimmen? Wirklich?” Tagesanzeiger Datenblog. https://blog.tagesanzeiger.ch/datenblog/index.php/668/je-weniger-auslaender-desto-mehr-ja-stimmen-wirklich.",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Infovis 1: Exercise</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis1_Script_eda.html",
    "href": "infovis/Infovis1_Script_eda.html",
    "title": "Infovis 1: EDA Script",
    "section": "",
    "text": "library(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"scales\")\n\n# create some data about age and height of people\npeople &lt;- data.frame(\n  ID = c(1:30),\n  age = c(\n    5.0, 7.0, 6.5, 9.0, 8.0, 5.0, 8.6, 7.5, 9.0, 6.0,\n    63.5, 65.7, 57.6, 98.6, 76.5, 78.0, 93.4, 77.5, 256.6, 512.3,\n    15.5, 18.6, 18.5, 22.8, 28.5, 39.5, 55.9, 50.3, 31.9, 41.3\n  ),\n  height = c(\n    0.85, 0.93, 1.1, 1.25, 1.33, 1.17, 1.32, 0.82, 0.89, 1.13,\n    1.62, 1.87, 1.67, 1.76, 1.56, 1.71, 1.65, 1.55, 1.87, 1.69,\n    1.49, 1.68, 1.41, 1.55, 1.84, 1.69, 0.85, 1.65, 1.94, 1.80\n  ),\n  weight = c(\n    45.5, 54.3, 76.5, 60.4, 43.4, 36.4, 50.3, 27.8, 34.7, 47.6,\n    84.3, 90.4, 76.5, 55.6, 54.3, 83.2, 80.7, 55.6, 87.6, 69.5,\n    48.0, 55.6, 47.6, 60.5, 54.3, 59.5, 34.5, 55.4, 100.4, 110.3\n  )\n)\n\n# build a scatterplot for a first inspection\nggplot(people, aes(x = age, y = height)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(people, aes(x = age, y = height)) +\n  geom_point() +\n  scale_y_continuous(limits = c(0.75, 2))\n\n\n\n\n\n\n\n# Go to help page: http://docs.ggplot2.org/current/ -&gt; Search for icon of fit-line\n# http://docs.ggplot2.org/current/geom_smooth.html\n\n\n# build a scatterplot for a first inspection, with regression line\nggplot(people, aes(x = age, y = height)) +\n  geom_point() +\n  scale_y_continuous(limits = c(0, 2.0)) +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n# stem and leaf plot\nstem(people$height)\n## \n##   The decimal point is 1 digit(s) to the left of the |\n## \n##    8 | 25593\n##   10 | 037\n##   12 | 523\n##   14 | 19556\n##   16 | 255789916\n##   18 | 04774\nstem(people$height, scale = 2)\n## \n##   The decimal point is 1 digit(s) to the left of the |\n## \n##    8 | 2559\n##    9 | 3\n##   10 | \n##   11 | 037\n##   12 | 5\n##   13 | 23\n##   14 | 19\n##   15 | 556\n##   16 | 2557899\n##   17 | 16\n##   18 | 0477\n##   19 | 4\n\n\n# explore the two variables with box-whiskerplots\nsummary(people$age)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    5.00    8.70   30.20   59.14   65.15  512.30\nboxplot(people$age)\n\n\n\n\n\n\n\n\n\nsummary(people$height)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.820   1.190   1.555   1.455   1.690   1.940\nboxplot(people$height)\n\n\n\n\n\n\n\n\n\n# explore data with a histogram\nggplot(people, aes(x = age)) +\n  geom_histogram(binwidth = 20)\n\n\n\n\n\n\n\n\n\ndensity(x = people$height)\n## \n## Call:\n##  density.default(x = people$height)\n## \n## Data: people$height (30 obs.);   Bandwidth 'bw' = 0.1576\n## \n##        x                y           \n##  Min.   :0.3472   Min.   :0.001593  \n##  1st Qu.:0.8636   1st Qu.:0.102953  \n##  Median :1.3800   Median :0.510601  \n##  Mean   :1.3800   Mean   :0.483553  \n##  3rd Qu.:1.8964   3rd Qu.:0.722660  \n##  Max.   :2.4128   Max.   :1.216350\n\n# re-expression: use log or sqrt axes\n#\n# Find here guideline about scaling axes\n# http://www.cookbook-r.com/Graphs/Axes_(ggplot2)/\n# http://docs.ggplot2.org/0.9.3.1/scale_continuous.html\n\n\n# logarithmic axis: respond to skewness in the data, e.g. log10\nggplot(people, aes(x = age, y = height)) +\n  geom_point() +\n  scale_y_continuous(limits = c(0, 2.0)) +\n  geom_smooth() +\n  scale_x_log10()\n\n\n\n\n\n\n\n\n\n# outliers: Remove very small and very old people\n\npeopleClean &lt;- people |&gt;\n  filter(ID != 27) |&gt; # This person was too short.\n  filter(age &lt; 100) # Error in age recorded.\n\n\nggplot(peopleClean, aes(x = age)) +\n  geom_histogram(binwidth = 10)\n\n\n\n\n\n\n\n\n\nggplot(peopleClean, aes(x = age, y = height)) +\n  geom_point() +\n  scale_y_continuous(limits = c(0, 2.0)) +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n# with custom binwidth\nggplot(peopleClean, aes(x = age)) +\n  geom_histogram(binwidth = 10) +\n  theme_bw() # specifying the theme\n\n\n\n\n\n\n\n\n\n# quadratic axis\nggplot(peopleClean, aes(x = age, y = height)) +\n  geom_point() +\n  scale_y_continuous(limits = c(0, 2.0)) +\n  geom_smooth(method = \"lm\", fill = \"lightblue\", size = 0.5, alpha = 0.5) +\n  scale_x_sqrt()\n\n\n\n\n\n\n\n\n\n# filter \"teenies\": No trend\nfilter(peopleClean, age &lt; 15) |&gt;\n  ggplot(aes(x = age, y = height)) +\n  geom_point() +\n  scale_y_continuous(limits = c(0, 2.0)) +\n  geom_smooth(method = \"lm\", fill = \"lightblue\", size = 0.5, alpha = 0.5)\n\n\n\n\n\n\n\n\n\n# filter \"teens\": No trend\npeopleClean |&gt;\n  filter(age &gt; 55) |&gt;\n  ggplot(aes(x = age, y = height)) +\n  geom_point() +\n  scale_y_continuous(limits = c(0, 2.0)) +\n  geom_smooth(method = \"lm\", fill = \"lightblue\", size = 0.5, alpha = 0.5)\n\n\n\n\n\n\n\n\n\n# Onwards towards multidimensional data\n\n# Finally, make a scatterplot matrix\npairs(peopleClean[, 2:4], panel = panel.smooth)\n\n\n\n\n\n\n\n\n\npairs(peopleClean[, 2:4], panel = panel.smooth)",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Infovis 1: EDA Script</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_A.html",
    "href": "infovis/Infovis2_Uebung_A.html",
    "title": "Infovis 2: Exercise A",
    "section": "",
    "text": "Task 1\nTransform the wide table into a long table using the following structure.\ntime\nstation\ntemperature\n\n\n\n\n2005-01-01\nALT\n1.3\n\n\n2005-01-01\nBUS\n1.5\n\n\n2005-01-01\nGVE\n1.1\n\n\n2005-01-01\nINT\n0.2\n\n\n2005-01-01\nOTL\n2.2\n\n\n2005-01-01\nLUG\n1.7\nNext, import the dataset temperature_2005_metadata.csv and join the two datasets with a left_join via station (or stn).",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Infovis 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_A.html#task-2",
    "href": "infovis/Infovis2_Uebung_A.html#task-2",
    "title": "Infovis 2: Exercise A",
    "section": "Task 2",
    "text": "Task 2\nCreate a scatter plot (time vs. temperature) where the points are coloured based on their sea level. Lower values should be coloured blue and higher values red (scale_colour_gradient). Reduce the size of the points to avoid excessive over-plotting of the points (size =). Furthermore, the respective month should be noted on the x-axis at intervals of 3 months (date_breaks and date_labels from scale_x_datetime()).",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Infovis 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_A.html#task-3",
    "href": "infovis/Infovis2_Uebung_A.html#task-3",
    "title": "Infovis 2: Exercise A",
    "section": "Task 3",
    "text": "Task 3\nCreate an additional Date variable with the date of the respective measurement (with as.Date()). Use this column to calculate the average daily temperature at each weather station (with summarise()).\nTo keep the metadata (Name, Meereshoehe, x, y), you can perform the join from the first exercise again. Alternatively (faster but also more advanced), you can use these variables within your group_by.",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Infovis 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_A.html#task-4",
    "href": "infovis/Infovis2_Uebung_A.html#task-4",
    "title": "Infovis 2: Exercise A",
    "section": "Task 4",
    "text": "Task 4\nNow repeat the plot from the first task with the aggregated data from the previous task. To set the labels correctly, you need to replace scale_x_datetime with scale_x_date.",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Infovis 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_A.html#task-5",
    "href": "infovis/Infovis2_Uebung_A.html#task-5",
    "title": "Infovis 2: Exercise A",
    "section": "Task 5",
    "text": "Task 5\nAdd a black, dashed trend line to the plot above.",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Infovis 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_A.html#task-6",
    "href": "infovis/Infovis2_Uebung_A.html#task-6",
    "title": "Infovis 2: Exercise A",
    "section": "Task 6",
    "text": "Task 6\nPosition the legend above the plot (use theme() with legend.position).",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Infovis 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_A.html#task-7-optional-advanced",
    "href": "infovis/Infovis2_Uebung_A.html#task-7-optional-advanced",
    "title": "Infovis 2: Exercise A",
    "section": "Task 7 (optional, advanced)",
    "text": "Task 7 (optional, advanced)\nAdd the temperature values on the y-axis with a °C (see below and this page for help)",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Infovis 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_A.html#task-8",
    "href": "infovis/Infovis2_Uebung_A.html#task-8",
    "title": "Infovis 2: Exercise A",
    "section": "Task 8",
    "text": "Task 8\nNow, let’s move away from the scatter plot and create a box plot with the temperature data. Colour the box plots again depending on the sea level.\n\nNote the difference between colour = and fill =\nNote the difference between facet_wrap() and facet_grid()\nRemember,facet_grid() requires a period (.) next to the tilde (~).\nNote the difference between “.~” and “~.” in facet_grid()\nAdjust the position of the legend as needed",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Infovis 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_A.html#task-9",
    "href": "infovis/Infovis2_Uebung_A.html#task-9",
    "title": "Infovis 2: Exercise A",
    "section": "Task 9",
    "text": "Task 9\nAs a final important plot type, let’s complete two exercises with histograms. First, create a histogram geom_histogram() with the temperature values, then allocate the weather stations to different altitude levels (Low altitude [[&lt; 400 m]], Mid altitude [[400 - 600 m]] and High altitude [[&gt; 600 m]]). Finally, compare the distribution of temperature values at the different altitudes using a histogram.\nTip: Use cut to divide the stations into the three groups",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Infovis 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_B.html",
    "href": "infovis/Infovis2_Uebung_B.html",
    "title": "Infovis 2: Exercise B (Optional)",
    "section": "",
    "text": "Task 1: Parallel Coordinate Plots\nCreate a parallel coordinate plot. For this, the integrated dataset mtcars is suitable. Extract the vehicle names with rownames_to_column.\nAlso, the values need to be normalised to a common scale. For this, you can use the function scales::rescale.\nHere’s what the finished plot looks like:",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Infovis 2: Exercise B (Optional)</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_B.html#task-2-polar-plot-with-beaver-data",
    "href": "infovis/Infovis2_Uebung_B.html#task-2-polar-plot-with-beaver-data",
    "title": "Infovis 2: Exercise B (Optional)",
    "section": "Task 2: Polar Plot with Beaver Data",
    "text": "Task 2: Polar Plot with Beaver Data\nPolar plots are suitable for data of a cyclical nature, such as time-stamped data (daily, weekly, or annual rhythms). From the example datasets, I found two datasets that are time-stamped:\n\nbeaver1 and beaver2\nAirPassenger\n\nBoth datasets need to be reshaped a bit before we can use them for a radial plot. In task 2, we’ll use the beaver datasets, and in task 3 we’ll use the passenger datasets.\nIf we want to use the data from both beavers, we need to merge them.\nWe also need to make some adjustments to the time data. According to the dataset’s description, time has been recorded in a format that isn’t very intuitive for programming purposes. For instance, 3:30 has been recorded as “0330”. To make this data more manageable, we’ll need to convert this time format into a decimal system.\nHere’s what the finished plot should look like:",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Infovis 2: Exercise B (Optional)</span>"
    ]
  },
  {
    "objectID": "infovis/Infovis2_Uebung_B.html#task-3-grid-visualisation-with-air-passengers",
    "href": "infovis/Infovis2_Uebung_B.html#task-3-grid-visualisation-with-air-passengers",
    "title": "Infovis 2: Exercise B (Optional)",
    "section": "Task 3: Grid Visualisation with Air Passengers",
    "text": "Task 3: Grid Visualisation with Air Passengers\nSimilar to task 2, this time we’ll use the AirPassengers dataset.\nThe AirPassengers dataset is in a unique format. At first glance, it might seem like a data.frame or a matrix. However, it’s actually a ts class object\nTo use this dataset, we first need to convert it into a matrix. I learned how to do this here.\nWe also need to convert the matrix into a dataframe, and to transform the wide table into a long table.\nHere’s what the finished plot looks like:",
    "crumbs": [
      "Information Visualisation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Infovis 2: Exercise B (Optional)</span>"
    ]
  },
  {
    "objectID": "Statistic.html",
    "href": "Statistic.html",
    "title": "Statistic",
    "section": "",
    "text": "Write Intro\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\nLesson\n\n\nTopic\n\n\n\n\n\n\nPreparation\n\n\n2024-04-02\n\n\nstat1\n\n\nPreparation\n\n\n\n\nStatistic 1\n\n\n2024-04-02\n\n\nstat1\n\n\nStatistic 1\n\n\n\n\nStatistic 2\n\n\n2024-04-09\n\n\nstat2\n\n\nStatistic 2\n\n\n\n\nStatistic 3\n\n\n2024-04-23\n\n\nstat3\n\n\nStatistic 3\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Statistic"
    ]
  },
  {
    "objectID": "statistic/Stat0_Vorbereitung.html",
    "href": "statistic/Stat0_Vorbereitung.html",
    "title": "Preparation",
    "section": "",
    "text": "As part of Statistic 1 - 3, we will need some R packages. We recommend installing them before the first lesson. Similar to the preparation exercise in Prepro1 you can use the code below to automatically install all packages that have not yet been installed.\n\nipak &lt;- function(pkg) {\n  new.pkg &lt;- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n  if (length(new.pkg)) {\n    install.packages(new.pkg, dependencies = TRUE)\n  }\n}\n\npackages &lt;- c('dplyr'\n \n)\n\nipak(packages)\n\nYou can also download the data for the exercises on Moodle.",
    "crumbs": [
      "Statistic",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Preparation</span>"
    ]
  },
  {
    "objectID": "statistic/Stat1_Uebung.html",
    "href": "statistic/Stat1_Uebung.html",
    "title": "Statistic 1",
    "section": "",
    "text": "The basics, comparisons of two samples, ANOVA, Regression techniques (linear, multiple, non-linear)",
    "crumbs": [
      "Statistic",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Statistic 1</span>"
    ]
  },
  {
    "objectID": "statistic/Stat2_Uebung.html",
    "href": "statistic/Stat2_Uebung.html",
    "title": "Statistic 2",
    "section": "",
    "text": "Advanced applications of inductive and multivariate statistics, …",
    "crumbs": [
      "Statistic",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Statistic 2</span>"
    ]
  },
  {
    "objectID": "statistic/Stat3_Uebung.html",
    "href": "statistic/Stat3_Uebung.html",
    "title": "Statistic 3",
    "section": "",
    "text": "Cluster analysis and data classification approaches",
    "crumbs": [
      "Statistic",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Statistic 3</span>"
    ]
  },
  {
    "objectID": "SpatAn.html",
    "href": "SpatAn.html",
    "title": "Spatial Analysis",
    "section": "",
    "text": "Part 1\nThe first exercise introduces the basics of loading and displaying geospatial data in both vector and raster formats. It also covers the fundamentals of coordinate systems and vector-to-raster conversion. Initial analyses demonstrate the use of Spatial Joins and the annotation of points with attributes from enclosing vector data. Finally, the issue of spatial data aggregation dependency is addressed, illustrated by the Modifiable Areal Unit Problem (MAUP).",
    "crumbs": [
      "Spatial Analysis"
    ]
  },
  {
    "objectID": "SpatAn.html#part-2",
    "href": "SpatAn.html#part-2",
    "title": "Spatial Analysis",
    "section": "Part 2",
    "text": "Part 2\nThe second exercise focuses on processing and visualising geospatial datasets, starting with a point dataset on air quality measurement in Switzerland (specifically nitrogen dioxide (NO2) levels). Unlike the point dataset on water availability from the previous exercise, the air quality monitoring sites have an irregular spatial distribution. Nevertheless, the goal is to interpolate a continuous layer of air quality values across Switzerland. We begin with the Inverse Distance Weighting (IDW) interpolation method, followed by constructing Thiessen Polygons using a nearest-neighbor approach. The latter part of the exercise examines density distribution, utilising a dataset on the movement of red kites in Switzerland. A Kernel Density Estimation (KDE) will be used to calculate a continuous density distribution, providing an approximation of the habitat of this bird of prey species.",
    "crumbs": [
      "Spatial Analysis"
    ]
  },
  {
    "objectID": "spatan/Spatan0_Vorbereitung.html",
    "href": "spatan/Spatan0_Vorbereitung.html",
    "title": "Preparation",
    "section": "",
    "text": "As part of SpatAn 1 - 3, we will need some R packages. We recommend installing them before the first lesson. Similar to the preparation exercise in Prepro1 you can use the code below to automatically install all packages that have not yet been installed.\n\nipak &lt;- function(pkg) {\n  new.pkg &lt;- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n  if (length(new.pkg)) {\n    install.packages(new.pkg, dependencies = TRUE)\n  }\n}\n\npackages &lt;- c(\n  \"sf\", \"dplyr\", \"ggplot2\", \"spatstat.geom\", \"spatstat.explore\",\n  \"gstat\", \"tidyr\", \"terra\", \"tmap\"\n)\n\nipak(packages)\n\nYou can download the datasets for the exercises from Moodle:\n\nSpatAn1\nSpatAn2",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Preparation</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan1_Uebung_A.html",
    "href": "spatan/Spatan1_Uebung_A.html",
    "title": "SpatAn 1: Exercise A",
    "section": "",
    "text": "Task 1: Import vector data\nImport the kantone.gpkg and gemeinden.gpkg records as follows. These are geodata sets in the geopackage (“* .gpkg”) format, which is an alternative data format to the more well-known “Shapefiles” format.\ncantons &lt;- read_sf(\"datasets/rauman/kantone.gpkg\")\nmunicipalities &lt;- read_sf(\"datasets/rauman/gemeinden.gpkg\")\nLook at the imported records.",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>SpatAn 1: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan1_Uebung_A.html#task-1-import-vector-data",
    "href": "spatan/Spatan1_Uebung_A.html#task-1-import-vector-data",
    "title": "SpatAn 1: Exercise A",
    "section": "",
    "text": "Note\n\n\n\nYou will get the most information about sf objects if you look at the record in the console (by typing the variable name in the console). When using the RStudio Viewer, sf objects load very slowly and metadata is not displayed.",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>SpatAn 1: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan1_Uebung_A.html#task-2-visualise-data",
    "href": "spatan/Spatan1_Uebung_A.html#task-2-visualise-data",
    "title": "SpatAn 1: Exercise A",
    "section": "Task 2: Visualise data",
    "text": "Task 2: Visualise data\nA very simple way of visualising sf objects is to use the plot() function in base-R. Execute the specified R commands and study the resulting plots. What differences can you see? How do you explain these differences?\n\n# without max.plot = 1 will result in R per plot per column\nplot(municipalities, max.plot = 1)\n\n\n\n\n\n\n\n\n# Alternatively, you can also plot a specific column\nplot(cantons[\"KANTONSFLA\"])",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>SpatAn 1: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan1_Uebung_A.html#input-coordinate-systems",
    "href": "spatan/Spatan1_Uebung_A.html#input-coordinate-systems",
    "title": "SpatAn 1: Exercise A",
    "section": "Input: Coordinate systems",
    "text": "Input: Coordinate systems\nIn the above visualisation, the following is noticeable:\n\nthe X/Y axes have two very different number ranges (see the axis labels)\nthe outline of Switzerland looks different in the two datasets (cantons are compressed against municipalities)\n\nOf course, this has to do with the fact that the two data sets were recorded in different coordinate systems. Coordinate systems are abbreviated to CRS (Coordinate Reference System). The assigned coordinate systems can be queried with st_crs().\n\nst_crs(cantons)\n## Coordinate Reference System:\n##   User input: Undefined Cartesian SRS \n##   wkt:\n## ENGCRS[\"Undefined Cartesian SRS\",\n##     EDATUM[\"Unknown engineering datum\"],\n##     CS[Cartesian,2],\n##         AXIS[\"(E)\",east,\n##             ORDER[1],\n##             LENGTHUNIT[\"Meter\",1]],\n##         AXIS[\"(N)\",north,\n##             ORDER[2],\n##             LENGTHUNIT[\"Meter\",1]]]\nst_crs(municipalities)\n## Coordinate Reference System:\n##   User input: Undefined Cartesian SRS \n##   wkt:\n## ENGCRS[\"Undefined Cartesian SRS\",\n##     EDATUM[\"Unknown engineering datum\"],\n##     CS[Cartesian,2],\n##         AXIS[\"(E)\",east,\n##             ORDER[1],\n##             LENGTHUNIT[\"Meter\",1]],\n##         AXIS[\"(N)\",north,\n##             ORDER[2],\n##             LENGTHUNIT[\"Meter\",1]]]\n\nUnfortunately, no coordinate systems are assigned in our case. With a little experience, however, you can guess which coordinate system is used, because a lot of them can be ruled out. The three most common coordinate systems in Switzerland are as follows:\n\nCH1903 LV03: the old coordinate system of Switzerland\nCH1903+ LV95: the new coordinate system of Switzerland\nWGS84: a frequently used, global geodetic coordinate system, i.e., the coordinates are given in length and width (lat/lon).\n\nIt is important to determine the correct coordinate system on the basis of the coordinates shown in the geometry column. If you select a location by right clicking on map.geo.admin.ch, you can find the coordinates of this location in various coordinate reference systems.\n\n\nIf you compare these coordinates with the coordinates of our data sets, it quickly becomes clear that the cantons dataset is the coordinate reference system (CRS) WGS84. We can use this information to set the CRS of our dataset with st_set_crs().\n\n# Assign with st_set_crs()...\ncantons &lt;- st_set_crs(cantons, \"WGS84\")\n\nIf we now retrieve the CRS information, we should see that this task has been successfully completed.\n\n# ... query with st_crs()\nst_crs(cantons)\n## Coordinate Reference System:\n##   User input: WGS84 \n##   wkt:\n## GEOGCRS[\"WGS 84\",\n##     DATUM[\"World Geodetic System 1984\",\n##         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"geodetic latitude (Lat)\",north,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         AXIS[\"geodetic longitude (Lon)\",east,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     ID[\"EPSG\",4326]]\n\nIt is a bit more complicated if we want to set the CRS of the municipalities dataset. In comparison with map.geo.admin.ch, we can see that this must be the CRS CH1903+ LV95. Using this name for our CRS assignment won’t work:\n\n# Assign with st_set_crs()...\nmunicipalities &lt;- st_set_crs(municipalities, \"CH1903+ LV95\")\n\n# ... query with st_crs()\nst_crs(municipalities)\n## Coordinate Reference System: NA\n\nThe advertised names of these CRSs are prone to errors. Therefore, it is better to work with the respective EPSG codes of the reference systems. These EPSG codes can be found on the following website: epsg.io/map. It is worth noting the EPSG codes of the relevant CRS:\n\nCH1903 LV03: EPSG:21781\nCH1903+ LV95: EPSG:2056\nWGS84: EPSG:4326\n\nWe can use this code to set the CRS of the municipalities dataset:\n\n# Assign with st_set_crs()...\nmunicipalities &lt;- st_set_crs(municipalities, 2056)\n\n# ... query with st_crs()\nst_crs(municipalities)\n## Coordinate Reference System:\n##   User input: EPSG:2056 \n##   wkt:\n## PROJCRS[\"CH1903+ / LV95\",\n##     BASEGEOGCRS[\"CH1903+\",\n##         DATUM[\"CH1903+\",\n##             ELLIPSOID[\"Bessel 1841\",6377397.155,299.1528128,\n##                 LENGTHUNIT[\"metre\",1]]],\n##         PRIMEM[\"Greenwich\",0,\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         ID[\"EPSG\",4150]],\n##     CONVERSION[\"Swiss Oblique Mercator 1995\",\n##         METHOD[\"Hotine Oblique Mercator (variant B)\",\n##             ID[\"EPSG\",9815]],\n##         PARAMETER[\"Latitude of projection centre\",46.9524055555556,\n##             ANGLEUNIT[\"degree\",0.0174532925199433],\n##             ID[\"EPSG\",8811]],\n##         PARAMETER[\"Longitude of projection centre\",7.43958333333333,\n##             ANGLEUNIT[\"degree\",0.0174532925199433],\n##             ID[\"EPSG\",8812]],\n##         PARAMETER[\"Azimuth of initial line\",90,\n##             ANGLEUNIT[\"degree\",0.0174532925199433],\n##             ID[\"EPSG\",8813]],\n##         PARAMETER[\"Angle from Rectified to Skew Grid\",90,\n##             ANGLEUNIT[\"degree\",0.0174532925199433],\n##             ID[\"EPSG\",8814]],\n##         PARAMETER[\"Scale factor on initial line\",1,\n##             SCALEUNIT[\"unity\",1],\n##             ID[\"EPSG\",8815]],\n##         PARAMETER[\"Easting at projection centre\",2600000,\n##             LENGTHUNIT[\"metre\",1],\n##             ID[\"EPSG\",8816]],\n##         PARAMETER[\"Northing at projection centre\",1200000,\n##             LENGTHUNIT[\"metre\",1],\n##             ID[\"EPSG\",8817]]],\n##     CS[Cartesian,2],\n##         AXIS[\"(E)\",east,\n##             ORDER[1],\n##             LENGTHUNIT[\"metre\",1]],\n##         AXIS[\"(N)\",north,\n##             ORDER[2],\n##             LENGTHUNIT[\"metre\",1]],\n##     USAGE[\n##         SCOPE[\"Cadastre, engineering survey, topographic mapping (large and medium scale).\"],\n##         AREA[\"Liechtenstein; Switzerland.\"],\n##         BBOX[45.82,5.96,47.81,10.49]],\n##     ID[\"EPSG\",2056]]\n\nNow that the CRS of the datasets is known, we can use ggplot2 to visualise our data. In InfoVis 1 & 2, we worked intensively with ggplot2 and got to know the geom_point() and geom_line() layers. ggplot() is also able to very easily plot vector data with geom_sf().\n\n\nSample Solution\nggplot() +\n  # In geom_sf neither x nor y axes need to be defined\n  geom_sf(data = municipalities)",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>SpatAn 1: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan1_Uebung_A.html#task-3-transform-coordinate-systems",
    "href": "spatan/Spatan1_Uebung_A.html#task-3-transform-coordinate-systems",
    "title": "SpatAn 1: Exercise A",
    "section": "Task 3: Transform coordinate systems",
    "text": "Task 3: Transform coordinate systems\nIn the previous exercise, we assigned a coordinate system but we did not manipulate the existing coordinates (in the geom column). It is quite different to transfer the data from one coordinate system to the other. In the process of transforming the system, the coordinates are converted and thus manipulated. For practical reasons,  we will transfer all our data into the new Swiss coordinate system CH1903+ LV95. Transform the cantons record with st_transform() into CH1903+ LV95, using the correct EPSG code.\nBefore transforming the data (consider the attributes Bounding box, Projected CRS as well as the values in the geomcolumn):\n\ncantons\n## Simple feature collection with 51 features and 6 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 5.955902 ymin: 45.81796 xmax: 10.49217 ymax: 47.80845\n## Geodetic CRS:  WGS 84\n## # A tibble: 51 × 7\n##    NAME       KANTONSNUM SEE_FLAECH KANTONSFLA KT_TEIL EINWOHNERZ\n##  * &lt;chr&gt;           &lt;int&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;        &lt;int&gt;\n##  1 Graubünden         18         NA     710530 0           197888\n##  2 Bern                2      11897     595952 1          1031126\n##  3 Valais             23       1060     522463 0           341463\n##  4 Vaud               22      39097     321201 1           793129\n##  5 Ticino             21       7147     281216 0           353709\n##  6 St. Gallen         17       7720     202820 1           504686\n##  7 Zürich              1       6811     172894 0          1504346\n##  8 Fribourg           10       7818     167142 1           315074\n##  9 Luzern              3       6438     149352 0           406506\n## 10 Aargau             19        870     140380 1           670988\n## # ℹ 41 more rows\n## # ℹ 1 more variable: geom &lt;POLYGON [°]&gt;\n\n\n\nSample Solution\ncantons &lt;- st_transform(cantons, 2056)\n\n\nAfter transferring the data (consider the Bounding box and Projected CRS attributes as well as the values in the geom column):\n\ncantons\n## Simple feature collection with 51 features and 6 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 2485410 ymin: 1075268 xmax: 2833858 ymax: 1295934\n## Projected CRS: CH1903+ / LV95\n## # A tibble: 51 × 7\n##    NAME       KANTONSNUM SEE_FLAECH KANTONSFLA KT_TEIL EINWOHNERZ\n##  * &lt;chr&gt;           &lt;int&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;        &lt;int&gt;\n##  1 Graubünden         18         NA     710530 0           197888\n##  2 Bern                2      11897     595952 1          1031126\n##  3 Valais             23       1060     522463 0           341463\n##  4 Vaud               22      39097     321201 1           793129\n##  5 Ticino             21       7147     281216 0           353709\n##  6 St. Gallen         17       7720     202820 1           504686\n##  7 Zürich              1       6811     172894 0          1504346\n##  8 Fribourg           10       7818     167142 1           315074\n##  9 Luzern              3       6438     149352 0           406506\n## 10 Aargau             19        870     140380 1           670988\n## # ℹ 41 more rows\n## # ℹ 1 more variable: geom &lt;POLYGON [m]&gt;",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>SpatAn 1: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan1_Uebung_A.html#task-4-tidyverse-functions",
    "href": "spatan/Spatan1_Uebung_A.html#task-4-tidyverse-functions",
    "title": "SpatAn 1: Exercise A",
    "section": "Task 4: Tidyverse functions",
    "text": "Task 4: Tidyverse functions\nsf objects are essentially data.frames with a few metadata and a special geometry column. We can perform the same operations as with data.frames. For example, we can calculate the population density from the columns EINWOHNERZ and KANTONSFLA:\n\ncantons &lt;- cantons |&gt;\n  mutate(\n    # convert hectares to km2\n    area_km2 = KANTONSFLA / 100,\n    # calculate population density per km2\n    population_density = EINWOHNERZ / area_km2\n  )\n\nNow calculate the population density at the level of the municipalities.\n\nmunicipalities &lt;- municipalities |&gt;\n  mutate(\n    area_km2 = GEM_FLAECH / 100,\n    population_density = EINWOHNERZ / area_km2\n  )",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>SpatAn 1: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan1_Uebung_A.html#task-5-chloropleth-maps",
    "href": "spatan/Spatan1_Uebung_A.html#task-5-chloropleth-maps",
    "title": "SpatAn 1: Exercise A",
    "section": "Task 5: Chloropleth Maps",
    "text": "Task 5: Chloropleth Maps\nNow we want to colour the municipalities or the cantons according to their population density. As usual, we use the aes(fill = ...) method from ggplot().\n\n\nSample Solution\nggplot(cantons) +\n  geom_sf(aes(fill = population_density))\n\n\n\n\n\n\n\n\n\nThere are hardly any differences in colour, because the extremely high population density of Basel-Stadt (&gt;5,000 inhabitants per km2!) dominates the entire colour scale. Switzerland’s Statistical Atlas solves the problem by using classes with irregular thresholds and grouping all numbers &gt;2,000. We can reproduce this procedure with cut().\n\n# Threshold is the same as BFS \"Statistical Atlas of Switzerland\"\nbreaks = c(0, 50, 100, 150, 200, 300, 500, 750, 1000, 2000, Inf)\n\n# show classes based on thresholds\ncantons &lt;- cantons |&gt;\n    mutate(population_density_classes = cut(population_density, breaks))\n\n# Create a colour palette: The number of colours needed is the number of \"breaks\" minus 1\nncols &lt;- length(breaks) - 1\n\n# Create a colour palette (see RColorBrewer::display.brewer.all())\nred_yellow_green &lt;- RColorBrewer::brewer.pal(ncols, \"RdYlGn\")\n\n# Invert colour palette (to green-red-yellow)\ngreen_red_yellow &lt;- rev(red_yellow_green)\n\np_cantons &lt;- ggplot(cantons, aes(fill = population_density_classes)) +\n  geom_sf(colour = NA) +\n  scale_fill_manual(values = green_red_yellow) +\n  theme_void() +\n  theme(legend.position = \"none\")\n\nCreate the same classes for the population density of the communities and compare the plots.\n\n\nSample Solution\nmunicipalities &lt;- municipalities |&gt;\n  mutate(population_density_classes = cut(population_density, breaks))\n\np_municipalities &lt;- ggplot(municipalities, aes(fill = population_density_classes)) +\n  geom_sf(colour = NA) +\n  scale_fill_manual(values = green_red_yellow) +\n  theme_void() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cantons\n\n\n\n\n\n\n\n\n\n\n\n(b) Municipalities\n\n\n\n\n\n\n\nFigure 21.1: Comparing these depictions clearly shows the problems of MAUP",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>SpatAn 1: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan1_Uebung_B.html",
    "href": "spatan/Spatan1_Uebung_B.html",
    "title": "SpatAn 1: Exercise B",
    "section": "",
    "text": "For the upcoming exercise, we will work with the gruental.gpkg. data set. Import it into R. We also need the following libraries:\n\nlibrary(\"dplyr\")\nlibrary(\"sf\")\nlibrary(\"ggplot2\")\n\n\nTask 1: Geopackage “Layers”\nYou may have noticed the following warning message when importing the gruental.gpkg geopackage:\nWarning message:\nIn evalq((function (..., call. = TRUE, immediate. = FALSE, noBreaks. = FALSE,  :\n  automatically selected the first layer in a data source containing more than one.\nThis warning message indicates that the geopackage gruental.gpkg has several layers (rep. records) and only the first layer has been imported. Use the st_layers command to find out the layer names and then use them in st_read (as argument layer =) to import the layers individually and store them in variables (e.g., such as in the variables wiesen and baeume).\n\n\nSample Solution\nst_layers(\"datasets/rauman/gruental.gpkg\")\n## Driver: GPKG \n## Available layers:\n##   layer_name geometry_type features fields       crs_name\n## 1     wiesen       Polygon       37      1 CH1903+ / LV95\n## 2     baeume         Point      185      2 CH1903+ / LV95\n\nmeadows &lt;- read_sf(\"datasets/rauman/gruental.gpkg\", \"wiesen\")\ntrees &lt;- read_sf(\"datasets/rauman/gruental.gpkg\", \"baeume\")\n\n\n\n\nTask 2: Understanding the data sets\nTake some time to explore the two datasets. Use the visualisation options of ggplot (especially geom_sf). You can superimpose multiple geom_sf to represent multiple records at the same time.\nggplot(meadows) +\n  geom_sf(aes(fill = flaechen_typ)) +\n  geom_sf(data = trees) +\n  theme_void()\n\nggplot(meadows) +\n  geom_sf() +\n  geom_sf(data = trees, aes(colour = baum_typ)) +\n  theme_void()\n\n\n\nSample Solution\n\n\n\n\n\n\n\n\nFigure 22.1: Meadow areas are shown in different colours depending on type\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 22.2: Trees are shown in different colours depending on type\n\n\n\n\n\n\n\n\nTask 3: Spatial join with points\nWe now want to know whether each tree is in a meadow or not. To do this, we use the GIS technique spatial join as described in the lecture. Using sf, we can perform spatial joins with st_join. There are only left and innerjoins (see PrePro 1 & 2). The “links” points must be listed first, since we want to attach attributes to the points.\nNote that the output has a new column: flaechen_typ. This is empty (NA) if the corresponding tree is not in a meadow. How many trees are in a meadow and how many are not?\n\n\nSample Solution\ntrees_join &lt;- st_join(trees, meadows)\n\nnumber_in_meadow &lt;- sum(!is.na(trees_join$flaechen_typ))\nnumber_not_in_meadow &lt;- sum(is.na(trees_join$flaechen_typ))",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>SpatAn 1: Exercise B</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_A.html",
    "href": "spatan/Spatan2_Uebung_A.html",
    "title": "SpatAn 2: Exercise A",
    "section": "",
    "text": "Task 1\nAs a first step, we need to apply a 20m buffer to each tree. Use st_buffer to save the output as trees_20m. Now take a close look at trees_20m. What type of geometry does it now represent?\nSample Solution\ntrees_20m &lt;- st_buffer(trees_sample, 20)\nSample Solution\nggplot() +\n  geom_sf(data = meadows) +\n  geom_sf(data = trees_sample) +\n  geom_sf(data = trees_20m, fill = NA)\n\n\n\n\n\n\n\n\nFigure 23.1: Trees are displayed as points with a 20m buffer. Meadows are displayed in the background.",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>SpatAn 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_A.html#task-2",
    "href": "spatan/Spatan2_Uebung_A.html#task-2",
    "title": "SpatAn 2: Exercise A",
    "section": "Task 2",
    "text": "Task 2\nNow calculate the intersection of trees_20m and meadows with the st_intersection function and save the output as trees_meadows. Next explore trees_meadows. What happened? Check the number of rows per record. Have they changed? If so, why?\n\n\nSample Solution\ntrees_meadows &lt;- st_intersection(trees_20m, meadows)\n\nggplot() +\n  geom_sf(data = meadows, fill = \"blue\", alpha = .2) +\n  geom_sf(data = trees_20m, fill = \"red\", alpha = .2) +\n  geom_sf(data = trees_meadows, fill = \"green\", alpha = 0.2)",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>SpatAn 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_A.html#task-3",
    "href": "spatan/Spatan2_Uebung_A.html#task-3",
    "title": "SpatAn 2: Exercise A",
    "section": "Task 3",
    "text": "Task 3\nNow calculate the area per geometry with the st_area() function. Save the output in a new column called trees_meadows (e.g. with the name meadow_area). Tip: Convert the output from st_area() to a numeric vector with as.numeric().\n\n\nSample Solution\ntrees_meadows$meadows_area &lt;- as.numeric(st_area(trees_meadows))",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>SpatAn 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_A.html#task-4-optional",
    "href": "spatan/Spatan2_Uebung_A.html#task-4-optional",
    "title": "SpatAn 2: Exercise A",
    "section": "Task 4 (Optional)",
    "text": "Task 4 (Optional)\nNow calculate the meadow_share from meadow_area. Tip: The circular area of \\(r^2\\times \\pi\\) is 100%, whereas in our case, $r = $20.\n\n\nSample Solution\narea_of_a_circle &lt;- 20^2 * pi\ntrees_meadows$meadows_share &lt;- trees_meadows$meadows_area / area_of_a_circle\n\n\nThen transfer the calculated proportional values to the trees dataset with a left_ join() between trees and trees_meadows. Which column would be suitable for this join? Note: Use st_drop_geometry() to remove the geometry column in trees_meadows before joining.\n\n\nSample Solution\ntrees_meadows_df &lt;- st_drop_geometry(trees_meadows)\n\ntrees_2 &lt;- left_join(trees_sample, trees_meadows_df, by = \"baum_id\")\n\nggplot() +\n  geom_sf(data = meadows) +\n  geom_sf(data = trees_2, aes(colour = meadows_share)) +\n  scale_color_binned(\"meadows share\", low = \"blue\", high = \"red\", limits = c(0, 1), label = scales::label_percent()) +\n  coord_sf(datum = 2056)\n\n\n\n\n\n\n\n\nFigure 23.2: After this exercise, you can visualise the results like this.",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>SpatAn 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_A.html#sec-raster-intro1",
    "href": "spatan/Spatan2_Uebung_A.html#sec-raster-intro1",
    "title": "SpatAn 2: Exercise A",
    "section": "Task 5",
    "text": "Task 5\nBy now you have performed a few vector operations such as st_buffer() and st_intersection() and st_area(). However, certain questions are better answered using the raster format. For example, if we want to know how far the nearest tree is for each point in the room, this can be better represented in a raster.\nHowever, before we can answer that question, we have to convert the vector data set into a raster data set. To do this, a raster “template” is needed so that R knows roughly what the raster output should look like.\n\n\nSample Solution\n# Use the \"terra\" package to work with the raster format.\nlibrary(\"terra\")\n\n# We need a template to vectorise data \n# We will use \"meadows\" as a template and set the cell size (resolution)\ntemplate &lt;- rast(meadows, resolution = 20)\n\n# When we rasterise, we convert \"trees\" into a raster format\n# Use all trees, not trees_sample\ntrees_rast &lt;- terra::rasterize(trees, template)\n\n\nThe difference between raster and vector can be shown very vividly if the two data sets are stored one on top of the other.\n\n\nSample Solution\nplot(trees_rast, col = \"grey\")\nplot(trees, add = TRUE, col = \"red\", pch = \"x\")\n\n\n\n\n\n\n\n\n\nwe can now use the function distance() with trees_rast to calculate the distance to each tree:\n\n\nSample Solution\ntrees_dist &lt;- distance(trees_rast)\nplot(trees_dist)\nplot(trees, add = TRUE, pch = \"x\")",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>SpatAn 2: Exercise A</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_B.html",
    "href": "spatan/Spatan2_Uebung_B.html",
    "title": "SpatAn 2: Exercise B",
    "section": "",
    "text": "Task 1\nIn this exercise, we will continue to work with terra to show how we can import, visualise and further process a raster dataset. In your data you will find a dataset called dhm250m.tif, which represents the “Digital Elevation Model” (DHM) of the Canton of Schwyz. Execute the specified code.\nlibrary(\"terra\")\nImport your raster with the rast() function\ndhm_schwyz &lt;- rast(\"datasets/rauman/dhm250m.tif\")\nYou will get some important metadata about the raster data when you enter the variable name in the console.\ndhm_schwyz\n## class       : SpatRaster \n## dimensions  : 150, 186, 1  (nrow, ncol, nlyr)\n## resolution  : 250, 250  (x, y)\n## extent      : 2672175, 2718675, 1193658, 1231158  (xmin, xmax, ymin, ymax)\n## coord. ref. : CH1903+ / LV95 (EPSG:2056) \n## source      : dhm250m.tif \n## name        :   dhm250m \n## min value   :  389.1618 \n## max value   : 2850.0203\nTo get a quick overview of a raster record, we can simply use the plot() function.\nplot(dhm_schwyz)\nUnfortunately, using raster data in ggplot is not very easy. Since ggplot() is a universal plot framework, we quickly reach the limits of what is possible when we create something as special as a map. Plot allows us to work very quickly, but again, it has its limits.\nFor this reason, we will introduce a new plot framework that specialises in maps and is built in a very similar design to ggplot: tmap. Load this package into your session now:\nlibrary(\"tmap\")\nJust like ggplot(), tmap is based on the idea of “layers” connected by a +. Each level has two components:\nSample Solution\ntm_shape(dhm_schwyz) +\n  tm_raster()\nNote that tm_shape() and tm_raster() (in this case) cannot exist without each other.\nIf you consult?tm_raster, you will see a variety of options that you can how your data is visualised. For example, the default style of tm_raster() creates “bins” with a discrete colour gamut. We can override this with style = \"cont\".\nSample Solution\ntm_shape(dhm_schwyz) +\n  tm_raster(style = \"cont\")\nThat should look appropriate, but maybe we want to change the default colour palette. Fortunately, this is much easier in tmap than in ggplot2. To view the available palettes, enter tmaptools ::palette_explorer() or RColorBrewer:: display.brewer.all() in the console (for the former, you may need to install additional packages, e.g. shinyjs).\nSample Solution\ntm_shape(dhm_schwyz) +\n  tm_raster(style = \"cont\", palette = \"Spectral\")\nOne of tmap’s great strengths is the fact that both static and interactive plots can be created with the same command. For this, you need to change the mode from static to interactive.\nSample Solution\ntmap_mode(\"view\") # changes to interactive Plots\n\ntm_shape(dhm_schwyz) +\n  tm_raster(style = \"cont\", palette = \"Spectral\")\n\n\n\n\n\n\nSample Solution\n\ntmap_mode(\"plot\") # changes back to static plots",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>SpatAn 2: Exercise B</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_B.html#task-1",
    "href": "spatan/Spatan2_Uebung_B.html#task-1",
    "title": "SpatAn 2: Exercise B",
    "section": "",
    "text": "a dataset component that is always tm_shape(dataset) (replace dataset with your variable)\na geometry component that describes how the previous tm_shape() should be visualised. This can be tm_dots() for points, tm_polygons() for polygons, tm_lines() for lines, etc. For single band raster (which is the case with dhm_ schwyz), use tm_raster()",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>SpatAn 2: Exercise B</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_B.html#sec-raster-slope",
    "href": "spatan/Spatan2_Uebung_B.html#sec-raster-slope",
    "title": "SpatAn 2: Exercise B",
    "section": "Task 2",
    "text": "Task 2\nUsing terra, we can run a variety of raster operations on our elevation model. A classic raster operation is the calculation of a slope’s incline (“slope”) or its orientation (“aspect”). Use the terrain() function from terra to calculate the slope inclination and orientation. Visualise the results.\n\n\nSample Solution\nterrain(dhm_schwyz, \"slope\") |&gt;\n  plot()\n\n\n\n\n\n\n\n\n\n\n\nSample Solution\nschwyz_aspect &lt;- terrain(dhm_schwyz, \"aspect\")\n\nplot(schwyz_aspect)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n“aspect” is a value that ranges from 0 to 360. In classic pallets, the two extreme values (in this case 0 and 360) are far apart in terms of colour. In aspect, however, these should be close together (since an orientation of 1° is only 2 degrees away from an orientation of 359°). To take this fact into account, we can create our own colour palette, where the first colour is repeated.\n\n\n\n\nSample Solution\ntm_shape(schwyz_aspect) +\n  tm_raster(\n    palette = c(\"#EF476F\", \"#FFD166\", \"#06D6A0\", \"#118AB2\", \"#EF476F\"),\n    style = \"cont\", breaks = seq(0, 360, 90)\n  )",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>SpatAn 2: Exercise B</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_B.html#task-3",
    "href": "spatan/Spatan2_Uebung_B.html#task-3",
    "title": "SpatAn 2: Exercise B",
    "section": "Task 3",
    "text": "Task 3\nUsing slope incline and orientation, we can calculate a hill shading effect. Hill shading refers to the shadow cast on the surface model and is calculated at a given angle of the sun (height and azimuth). The typical angle is 45° above the horizon and 315° from the northwest.\nTo create a hill shading effect, first calculate slope and aspect of dhm_schwyz, just like in the previous task, but make sure that the unit corresponds to the radians. Use these two objects in the shade() function to calculate the hill shade. Then visualise the output with plot or tmap.\n\n\nSample Solution\ndhm_slope &lt;- terrain(dhm_schwyz, \"slope\", unit = \"radians\")\ndhm_aspect &lt;- terrain(dhm_schwyz, \"aspect\", unit = \"radians\")\n\ndhm_hillshade &lt;- shade(dhm_slope, dhm_aspect, 45, 315)\n\ntm_shape(dhm_hillshade) +\n  tm_raster(style = \"cont\", palette = \"cividis\", legend.show = FALSE) +\n  tm_layout(frame = FALSE)\n\n\n\n\n\nUse tmap for this visualisation along side the cividis colour palette",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>SpatAn 2: Exercise B</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_C.html",
    "href": "spatan/Spatan2_Uebung_C.html",
    "title": "SpatAn 2: Exercise C1",
    "section": "",
    "text": "Task 1: Visualise red kite movement data\nThe first question typically asked in such movement studies is: where can this bird usually be found? To answer this question, the first thing to do is simply visualise the data points in a simple map. Create the map below to answer this question.\nSample Solution\nggplot(switzerland) +\n  geom_sf() +\n  geom_sf(data = red_kites) +\n  theme_void()",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>SpatAn 2: Exercise C1</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_C.html#task-2-calculate-kernel-density-estimation",
    "href": "spatan/Spatan2_Uebung_C.html#task-2-calculate-kernel-density-estimation",
    "title": "SpatAn 2: Exercise C1",
    "section": "Task 2: Calculate Kernel Density Estimation",
    "text": "Task 2: Calculate Kernel Density Estimation\nAt first, this approach appears to work, but here we encounter the typical problem of “overplotting”. This means that due to the overlay of many points in dense regions, we cannot estimate how many points are actually there and potentially overlapping. There are various ways to visualise the point density more clearly. A very popular method among biologists is density distribution with a Kernel Density Estimation (KDE). This is mainly because the habitat (home range) of an animal can be estimated using KDE. Home ranges are often defined with KDE95 and core areas are defined with KDE50 (Fleming C., Calabrese J., 2016).\nTo calculate the density, we use the density.ppp function fromspatstat. This library is somewhat complex to use, but so that we can still apply this method to our red kite data, we have created our own KDE function.\nWe encourage those of you who can study our function in detail to not use it, and instead to use spatstat directly. If you want to work with our function, you’ll need to copy and execute the code below into your script.\n\nmy_kde &lt;- function(points, cellsize, bandwith, extent = NULL){\n  library(\"spatstat.geom\")    # to convert to ppp\n  library(\"spatstat.explore\") # to calculate density\n\n  points_ppp &lt;- as.ppp(points) # convert sf &gt; ppp\n\n  if(!is.null(extent)){\n    # if an extent has been given, this will be used\n    # to set the observation window\n    Window(points_ppp) &lt;- as.owin(st_bbox(extent))\n  }\n\n  # Calculate density\n  points_density &lt;- density.ppp(x = points_ppp, sigma = bandwith, eps = cellsize)\n\n  # Convert Output in a DataFrame\n  points_density_df &lt;- as.data.frame(points_density)\n\n  points_density_df\n}\n\nThe parameters of the function should be relatively clear:\n\npoints: a point record from the class sf\ncellsize: the cell size of the output grid\nbandwith: The search radius for the density calculation\nextent (optional): the perimeter in which the density distribution is to be calculated. If no perimeter is specified, the “bounding box” of points should be used.\n\nIf we now use my_kde() to calculate density distribution, we get a data.frame with X and Y coordinates and a value column. Use these three columns with geom_raster() to visualise your data with ggplot aes(x = X, y = Y, fill = value).\n\nred_kites_kde &lt;- my_kde(points = red_kites, cellsize = 1000, bandwith = 10000, extent = switzerland)\n\nhead(red_kites_kde)\n##         x       y        value\n## 1 2485909 1075767 5.706506e-24\n## 2 2485909 1076766 8.289075e-23\n## 3 2485909 1077764 3.029525e-23\n## 4 2485909 1078763 6.521282e-23\n## 5 2485909 1079761 9.598037e-23\n## 6 2485909 1080760 1.182799e-22\n\n\n\nSample Solution\nggplot() +\n  geom_raster(data = red_kites_kde, aes(x, y, fill = value)) +\n  geom_sf(data = switzerland, fill = NA) +\n  scale_fill_viridis_c() +\n  theme_void()\n\n\n\n\n\n\n\n\n\nThe kernel density estimation is now very much dominated by low values, as the density in most cells of our study area is close to zero. As mentioned, scientists are often only interested in the highest 95% of values. Follow these steps to depict results a little better:\n\nCalculate the 95th percentile of all values with the function quantile and name this q95\nCreate a new column in red_kites_kde in which all values are lower than q95 NA\n(Optional): Transform the values with log10 to get a more differentiated gradient\n\nWe can hide the low values by representing only the highest 5% of the values. To accomplish this, we use raster::quantile to calculate the 95th percentile of all values and use this value as a “limit value” for the representation.\nIn addition, a logarithmic transformation of the values helps to make the colour scale somewhat more visible.\n\n\nSample Solution\nq95 &lt;- quantile(red_kites_kde$value, probs = 0.95)\n\nred_kites_kde &lt;- red_kites_kde |&gt;\n  mutate(\n    value_new = ifelse(value &gt; q95, value, NA),\n    value_new = log10(value_new)\n  )\n\nggplot() +\n  geom_raster(data = red_kites_kde, aes(x, y, fill = value_new)) +\n  geom_sf(data = switzerland, inherit.aes = FALSE, fill = NA) +\n  scale_fill_viridis_c(na.value = NA) +\n  theme_void()",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>SpatAn 2: Exercise C1</span>"
    ]
  },
  {
    "objectID": "spatan/Spatan2_Uebung_C.html#task-3-density-distribution-with-thiessen-polygons",
    "href": "spatan/Spatan2_Uebung_C.html#task-3-density-distribution-with-thiessen-polygons",
    "title": "SpatAn 2: Exercise C1",
    "section": "Task 3: Density distribution with Thiessen polygons",
    "text": "Task 3: Density distribution with Thiessen polygons\nThiessen polygons offer an exciting alternative for visualising differences in the density distribution of points in data sets. We now want to try this out and construct Thiessen polygons for the red kite data in Switzerland. Use the instructions for creating Thiessen polygons from exercise B to create Thiessen polygons for the red kite positions.\n\n\nSample Solution\nthiessenpolygone &lt;- red_kites |&gt;\n  st_union() |&gt;\n  st_voronoi()\nswitzerland &lt;- st_union(switzerland)\n\nthiessenpolygone &lt;- st_cast(thiessenpolygone)\n\nthiessenpolygone_clip &lt;- st_intersection(thiessenpolygone, switzerland)\n\n\n\n\nSample Solution\nggplot() +\n  geom_sf(data = switzerland) +\n  geom_sf(data = thiessenpolygone_clip, fill = NA) +\n  theme_void()\n\n\n\n\n\n\n\n\nFigure 25.1: It will be clearer if we depict Thiessen polygons without points, just how density within clusters appears",
    "crumbs": [
      "Spatial Analysis",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>SpatAn 2: Exercise C1</span>"
    ]
  },
  {
    "objectID": "References.html",
    "href": "References.html",
    "title": "References",
    "section": "",
    "text": "Kovic, Marko. 2014. “Je Weniger Ausländer, Desto Mehr Ja-Stimmen?\nWirklich?” Tagesanzeiger Datenblog. https://blog.tagesanzeiger.ch/datenblog/index.php/668/je-weniger-auslaender-desto-mehr-ja-stimmen-wirklich.\n\n\nScherler, Patrick. 2020. “Drivers of Departure and Prospecting in\nDispersing Juvenile Red Kites (Milvus Milvus).” PhD thesis,\nUniversity of Zurich.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data\nScience. O’Reilly. https://ebookcentral.proquest.com/lib/zhaw/detail.action?docID=4770093.",
    "crumbs": [
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>References</span>"
    ]
  }
]